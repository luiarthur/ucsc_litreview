\documentclass[12pt,]{article}

%{{{1
%\usepackage{lmodern}
\usepackage{amssymb,amsmath}
%\usepackage{ifxetex,ifluatex}
%\usepackage{fixltx2e} % provides \textsubscript
%\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
%  \usepackage[T1]{fontenc}
%  \usepackage[utf8]{inputenc}
%\else % if luatex or xelatex
%  \ifxetex
%    \usepackage{mathspec}
%  \else
%    \usepackage{fontspec}
%  \fi
%  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
%\fi
% use upquote if available, for straight quotes in verbatim environments
%\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
%% use microtype if available
%\IfFileExists{microtype.sty}{%
%\usepackage{microtype}
%\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
%}{}
\usepackage{setspace}
\usepackage[margin=1in]{geometry}
\usepackage[unicode=true]{hyperref}
\hypersetup{
            pdftitle={Sampling Scheme for CYTOF Model3},
            pdfauthor={Arthur Lui},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{plainnat}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
%\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\usepackage{bm}
\usepackage{bbm}
\usepackage{graphicx}

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\p}[1]{\left(#1\right)}
\newcommand{\bk}[1]{\left[#1\right]}
\newcommand{\bc}[1]{ \left\{#1\right\} }
\newcommand{\abs}[1]{ \left|#1\right| }
\newcommand{\mat}{ \begin{pmatrix} }
\newcommand{\tam}{ \end{pmatrix} }
\newcommand{\suml}{ \sum_{i=1}^n }
\newcommand{\prodl}{ \prod_{i=1}^n }
\newcommand{\ds}{ \displaystyle }
\newcommand{\df}[2]{ \frac{d#1}{d#2} }
\newcommand{\ddf}[2]{ \frac{d^2#1}{d{#2}^2} }
\newcommand{\pd}[2]{ \frac{\partial#1}{\partial#2} }
\newcommand{\pdd}[2]{\frac{\partial^2#1}{\partial{#2}^2} }
\newcommand{\N}{ \mathcal{N} }
\newcommand{\E}{ \text{E} }
\def\given{~\bigg|~}
\usepackage{float}
\restylefloat{table}
\def\beginmyfig{\begin{figure}[H]\center}
\def\endmyfig{\end{figure}}
\newcommand{\iid}{\overset{iid}{\sim}}
\newcommand{\ind}{\overset{ind}{\sim}}
\newcommand{\I}{\mathrm{\mathbf{I}}}

\def\bet{\bm{\eta}}


\allowdisplaybreaks
\def\M{\mathcal{M}}
\def\logit{\text{logit}}
\def\Bern{\text{Bernoulli}}
\def\N{\text{N}}
\def\G{\text{Ga}}
\def\IG{\text{Inverse-Gamma}}
\def\Dir{\text{Dirichlet}}
\def\Ber{\text{Ber}}
\def\Be{\text{Be}}
\def\lin{\lambda_{in}}
\def\btheta{\bm{\theta}}
\def\y{\bm{y}}
\newcommand\m{\bm{m}}
\def\mus{\mu^\star}
\def\sss{{\sigma^2}^\star}
\input{includes/mhSpiel.tex}
\newcommand{\Ind}[1]{\mathbbm{1}\bc{#1}}
\def\rest{\text{rest}}
\def\bang{\boldsymbol{\cdot}}
\def\h{\bm{h}}
\def\Z{\bm{Z}}
\def\Unif{\text{Unif}}
\def\Prob{\text{Pr}}


%sim-tex-commands
\newcommand{\true}{{\mbox{\tiny TR}}}
\newcommand{\bZ}{\mbox{\boldmath $Z$}}
\newcommand{\bp}{\mbox{\boldmath $p$}}
\newcommand{\bq}{\mbox{\boldmath $q$}}
\newcommand{\bz}{\mbox{\boldmath $z$}}
\newcommand{\bw}{\mbox{\boldmath $w$}}
\newcommand{\bW}{\mbox{\boldmath $W$}}
\newcommand{\bI}{\mbox{\boldmath $I$}}

\newcommand{\by}{\mbox{\boldmath $y$}}
%\newcommand{\bm}{\mbox{\boldmath $m$}}

\def\bmu{\bm{\mu}}
\def\bnu{\bm{\nu}}
\def\bomega{\bm{\omega}}
\def\bgam{\bm{\gamma}}
\def\bsig{\bm{\sigma}}
\def\blambda{\bm{\lambda}}
\def\TN{\text{TruncatedNormal}}

\usepackage[dvipsnames,usenames]{color}
\newcommand{\bch}{\color{blue}\it}
\newcommand{\ech}{\color{Black}\rm}
\renewcommand{\pm}{\color{BrickRed}\it}
\renewcommand{\mp}{\color{Black}\rm}
%\newcommand{\note}[1]{\footnote{\color{blue}\rm #1 \color{Black}}}

\newcommand{\yy}{\it} % \color{magenta}\it}
\newcommand{\yj}{\it} % \color{Orange}\it}
\newcommand{\jj}{\color{Black}\rm}
\newcommand{\note}[1]{\color{blue} {\sc [Note]}\footnote{\color{Brown}\rm #1
    \color{Black}} \color{Black}}

\newcommand{\hh}{\color{Mahogany}\it}



%%% Graphing
\def\beginmyfig{\begin{figure}[H]\center}
\def\endmyfig{\end{figure}}
\usepackage{pgffor}
%}}}1

\title{Bayesian Feature Allocation Models for Natural Killer Cell Repertoire
Studies Using Mass Cytometry Data}
\author{
  Arthur Lui\\
  %\thanks{This is a cool command}
  Department of Applied Mathematics and Statistics, UC Santa Cruz
}
\date{\today}

\begin{document}
\maketitle
\onehalfspacing



\begin{abstract}
\noindent
Bayesian feature allocation models (FAMs) embedded with clustering capabilities
are developed to analyze mass cytometry data, so as to characterize underlying
cell repertoire structures. Cell repertoires in samples are heterogeneous. Each
repertoire consists of a collection of cells possessing different phenotypes
that can be characterized by differences in expression levels of cell surface
markers.  In particular, mass cytometry data collected to study the clinical
efficacy of natural killer (NK) cells as immunotherapeutic agents against
leukemia are considered. NK cells play a critical role in cancer immune
surveillance and are the first line of defense against viruses and transformed
tumor cells.  The data of interest includes expression levels of 32 surface
markers on each of thousands of cells from multiple samples. NK cell
repertoires may affect both NK cell function and immune surveillance. We 
present a key conceptual shift from existing approaches by explicitly
characterizing latent cell phenotypes through a FAM. The models simultaneously
(1) characterize NK cell phenotypes based on expression / non-expression of
surface markers, (2) estimate compositions of the samples based on the
identified phenotypes, and (3) infer associations between subject-covariates
and the composition of the identified phenotypes in the samples.  The
conventional Indian buffet process (IBP), one of the most popular FAMs, is
first utilized to model cell phenotypes.  Non-ignorable missing data that is
present due to technical artifacts in mass cytometry instruments are accounted
for by using an informed prior missing mechanism. The repulsive FAM (rep-FAM)
is next proposed.  In contrast to the IBP, the rep-FAM produces a
parsimonious representation of the latent phenotypes by discouraging the
creation of redundant phenotypes, and can thus improve inference on phenotypes.
Further extensions to incorporate subject based covariates are discussed to
provide inferences on phenotypes potentially associated with positive clinical
outcomes.

%\noindent
%{\em Keywords:} ~  Count data, Laplace prior, Metagenomics, Microbiome,
%Regularizing prior, Process convolution,  Negative binomial model,
%Next-generation sequencing
\end{abstract}


\tableofcontents
\newpage

\section{Introduction}
Clinical application of natural killer (NK) cells
%as immunotherapeutic agents against leukemia
has recently emerged as a powerful treatment modality for advanced cancers
refractory to conventional therapies \citep{rezvani2015application}. 
%and intensely investigated.
%NK cells, the third lymphocyte lineage, % preceded by T cells and B cells,
%play critical roles in the immune response to certain %virus infected cells and
%transformed tumor cells.
NK cells play a critical role in cancer immune surveillance and are the first
line of defense against viruses and transformed tumor cells.  They have the
intrinsic ability to infiltrate cancer tissue and their presence in tumors is
reported to be associated with better clinical outcomes
\citep{suck2016natural}.  
%NK cells develop in the bone marrow and are ``educated'' during their
%development to ensure not to attack normal self cells whiling rapidly killing
%tumor or virally infected cells.
% (called self-tolerance).
%During the development,
Drs. Thall and Rezvani, collaborators at UT MD Anderson Cancer Center, have
conducted clinical trials to study the potential clinical efficacy of umbilical
cord blood (UCB) transplantation as a therapy for leukemia.  UCB has become an
established source of hematopoietic stem cells for transplantation. UCB NK cell
therapy has the advantage of low risk of viral transmission from donor to
recipient \citep{sarvaria2017umbilical}. In the trials, leukemia patients
received UCB cell transplants.
% after irradiation therapy.  %Some characteristics of the patients such as
% their survival after the treatment are recorded.
During follow-ups, samples were taken at multiple time points from each patient.
Samples from healthy subjects and cord blood samples also were collected for
comparison to leukemia patient samples.  The samples were processed and
expression levels of 32 NK-cell-associated cell surface protein markers were
measured for individual cells in the samples using mass cytometry.  Their
primary research goal is to understand phenotypes and functions structured
across heterogeneous NK cells.
% based on the markers' expression levels.
Better understanding of the characteristics of NK cells is crucial to
estimating the true potential of NK cell therapies against cancer.
%for cancer immunotherapy. %against leukemia and possibly also against solid
%tumors.



%NK cells play critical roles in defending against tumors. Furthermore, their diversity and function are
%known to be linked. Researchers have thus studied NK cell diversity from
%various perspectives. For instance, it is known that NK cell diversity
%is lower at birth \citep{strauss2015human} than in adults. Some
%researchers have studied the effect of introducing diverse NK cells into
%tumor patients. Yet again, some researchers have found that patients
%with higher NK diversity are associated with higher exposure risk of
%HIV-1, suggesting that existing diversity may decrease flexibility of
%the antiviral response. Many questions about NK cells remain to be
%answered. Understanding NK diversity through spectrometry has therefore
%been an important research area in the bio-sciences.   

%The main
%inferential goal of this project is to identify the NK cell phenotypes
%(or cell types) in various samples as a set of subpopulations of the set
%of some provided surface markers. The NK cell types are latent, and for
%$J$ markers $2^J$ different cell types can be considered. This
%provides a computational challenge when the number of markers is even
%moderately large. Thirty-two markers are included in this analysis, and
%naively enumerating all possible markers is not feasible. We therefore,
%use a latent feature allocation model to learn the latent structure of
%predominant cell types. Latent feature models have been successfully
%applied to various problems and will be reviewed in the following
%section.
%Data for this project is rendered through CyTOF analyses of
%NK-cell-targeting markers. Having some understanding of CyTOF and NK
%cells their importance is therefore necessary.



Advances in cytometry have led to more research and greater understanding of NK
cells and how their diversity impacts immunity against the development of
tumors and other viral diseases.  Flow cytometry has been routinely used for
single-cell analysis in cellular and clinical immunology.  A primary
interest in cytometry data analysis is to identify different cell types in a
heterogeneous population and measure their abundance.  Cell-types are
characterized by their distinct expression patterns of multivariate protein
markers, and expression patterns can be affected by cell composition and
biological function.
%Flow cytometry (developed by
%Wallace Coulter in the 1950's) is a laser-based biophysical technology which is
%sometimes used for biomarker detection. It is regularly used to diagnose health
%disorders like cancer. Cytometry has advanced over the years.
%Fluorescence-based flow cytometry, which makes use of fluorescent dyes and
%lasers that emit light at specific wavelengths, is one such advancement that
%has been mainstream for several decades \citep{herzenberg2002history}.  
In recent years, a new cytometry technique, Cytometry at time-of-flight (CyTOF,
also known as mass cytometry) has surfaced.  It makes use of time-of-flight
mass spectrometry, where sophisticated devices are used to accelerate,
separate, and identify ions by mass. This new method enables the detection of a
greater number of parameters (biological, phenotypic, or functional markers), up
to 40 parameters for a cell, in less time and at a higher resolution
\citep{cheung2011screening}. 
%Through CyTOF, scientists have been able to better understand natural killer
%(NK) cells \citep{horowitz2013genetic}. 
Efficient inferential frameworks are required to understand complex cytometry
data.  Manual ``gating'' is a traditional method in this realm in which
homogeneous cell-clusters are sequentially identified and refined using a set
of markers.  However, it has several serious shortcomings including its
inherent subjectivity as it requires manual analysis, and being unscalable for
multiparameter data.  While manual gating is still popular in practice, many
computational methods that automatically identify cell clusters have been
proposed to analyze high-dimensional cytometry data.  
%These data are often
%high-dimensional and noisy. Hence, many 
Many existing automated analysis methods use dimension reduction techniques
and/or clustering methods such as density-based clustering methods, model-based
clustering methods, and self-organizing maps.
% FLOWSOM
For example, FlowSOM in \cite{van2015flowsom} uses a self-organizing map (SOM),
an unsupervised neural network technique, for clustering and dimension
reduction. A low-dimensional representation of the input space is obtained
using unsupervised neural networks for easy visualization in a graph called a
map.  FlowSOM is fast and can be used as a starting point for a manual gating
or as a visualization tool after a gating.  Other common approaches are
density-based clustering methods including DBSCAN \citep{ester1996density} and
ClusterX \citep{chen2016cytofkit}, and  model-based clustering methods including
flowClust \citep{lo2009flowclust} and BayesFlow \citep{johnsson2016bayesflow}.
Density-based clustering methods like DBSCAN and ClusterX form clusters in data
when regions are densely occupied by observations. Observations from dense
clusters that are near-together enough according to some predetermined
proximity metric and threshold are grouped, while observations that are
considered far from dense regions are classified as outliers. Density-based
methods can produce clusters that take on flexible shapes. FlowClust clusters
Box-Cox transformed data using a mixture of t-distributions and provides
parameter estimates through expectation-maximization (EM) algorithm. BayesFlow
developed a Bayesian hierarchical model to cluster cells through a Gaussian
mixture model.  \cite{weber2016comparison} performed a study to compare freely
available clustering methods for high-dimensional cytometry data.  They
analyzed six publicly available cytometry datasets and compared identified cell
subpopulations to cell population identities known from expert manual gating. 


Existing methods, while promising, have fallen short at providing comprehensive
inference on the underlying cell phenotypes in cell populations.  Many of them
do not properly handle large sample-to-sample variations and abnormalities due
to technical artifacts in cytometry data, and do not provide uncertainty
measurements for resulting inferences.  Expression levels in different samples
can significantly vary due to technical variation and most existing methods
often analyze samples separately.  Moreover, observations can be missing due to
technical limitations when markers are not expressed.  Existing methods often
ignore missing data or use pre-imputed data.  More importantly, existing methods
do not directly model the underlying cell types.  Rather, they identify cell
clusters based on similarities in expression patterns and determine cell types
based on identified clusters. When cells have the same expression pattern but
different expression levels due to experimental noise, they can be grouped into
different clusters although they are likely to be of the same cell type.  We
will utilize Bayesian feature allocation models (FAMs) embedded with clustering
capabilities as our main tools to directly model cell types. FAMs will provide
a solid foundation to an effective way of revealing the underlying cell
phenotypes. We also propose mechanisms for imputing missing values within the
models. The proposed models will efficiently provide a full model-based and
probabilistic inference with honest uncertainty quantification.


%{\tt introduce some existing approaches.  Explain a bit the methods
%that we will use for comparison.  State limitations of existing methods.  Are
%they Bayesian?  Are they modeling phenotypes like our $\Z$.  Emphasize that our
%methods produce direct inferences on phenotypes or quantification of
%uncertainty associated with their inference.}
%
%{\tt include several examples of existing methods. explain what they do and
%produce for inference. explain what they miss.}
%
%To better understand the properties of these different methods, 
%\cite{weber2016comparison} performed a study which compares freely available
%clustering methods for high-dimensional cytometry data. These methods are based
%on a variety of techniques including hierarchical clustering methods , k-means,
%density-based clustering methods, model-based clustering methods,
%nearest-neighbor methods, and self-organizing maps. Each method exhibits their
%own strengths.
% kmeans
%In K-mean, one of the most well known clustering methods, observations are
%iteratively grouped into clusters based on their proximity to the $K$
%centroids, and then the centroids are updated based on the newly formed
%clusters. This method, while fast, memory-efficient, and intuitive, produces
%only point estimates of clusters. In addition, the number of clusters needs to
%be predetermined.
%This is a common trait among the clustering methods used in analyzing cytometry
%data.
% hclust
%In hierarchical clustering, no assumptions about the number of clusters are
%made, and the final output is a dendrogram, which can then be cut at different
%levels, forming clusters. However, these dendrograms are typically cut based on
%some visual criteria, which can be cumbersome.  Hierarchical clustering
%implementations also typically suffer from memory-related bottlenecks for large
%datasets.  Memory-efficient implementations suited for such datasets have been
%implemented in the statistical programming language R by
%\citep{linderman2013package}, making it a viable candidate method for cytometry
%data.
% nearest neighbors. phenograph @levine2015data
%Nearest-neighbor clustering methods like PhenoGraph \citep{levine2015data}
%similarly attempt to reduce the computational costs of hierarchical clustering
%methods by merging clusters by following paths in the nearest neighborhood
%graph of clusters.
%
%These mentioned hierarchical clustering methods do not provide uncertainty
%estimates.
%
% FLOWSOM
%Some methods, like FlowSOM \citep{van2015flowsom}, are able to learn the number
%of clusters in the data, while also allowing the number of clusters to be
%explicitly specified.  FlowSOM uses a self-organizing map (SOM) to reduce the
%dimensionality of cytometry data, and cluster them accordingly. Self-organizing
%maps are trained using unsupervised neural networks to obtain a low-dimensional
%representation of the input space. Since neural networks are capable of
%learning non-linear functions, SOMs may be considered a nonlinear
%generalization of principal components analysis \citep{yin2008learning}. In the
%FlowSOM implementation, the input space is projected onto a two-dimensional
%space and can be conveniently visualized in a graph called a map.
%Among existing methods FlowSOM is considered the fastest and most flexible at
%finding subpopulations in cytometry data. However, it does not quantify
%uncertainty about the learned clusters.
%% Write about density-based, model-based, and nearest neighbors.
% density-based. DBSCAN \citep{ester1996density}
%Another class of methods where the number of clusters does not need to be
%specified beforehand is density-based clustering methods. The earliest of these
%methods include DBSCAN \citep{ester1996density}. In density-based
%clustering, clusters are formed when regions are densely occupied by
%observations. Points from dense clusters that are near enough (according to
%some predetermined proximity metric and threshold) are grouped into the
%cluster. Points that are considered far from dense regions are classified as
%outliers. In general, density-based methods can produce clusters that take on
%very flexible shapes. But again, no uncertainty estimates are produced for
%these clusters. In addition, older implementations like DBSCAN can be
%computationally inefficient, having a worst-case complexity of
%$\mathcal{O}(n^2)$ (due to the computation and storage of the distance matrix). 
% density-based. ClusterX @chen2016cytofkit 
%ClusterX \citep{chen2016cytofkit} is a density-based clustering method used for
%cytometry data. It alleviates some computational and memory burdens by using a
%split-apply-combine strategy where the data are first split into smaller 
%manageable chunks so as to compute a smaller distance matrix. Parameters
%are computed for each small chunk and the results are combined. 
%
% model-based. flowClust @lo2009flowclust. 
%%%% - Uses mixture of t-dist on box-cox-transformed data
%%%% - model is fit using EM.
%%%% - Model is fit K times, each time with different number of clusters
%%%%      - using BIC, the number of clusters is chose
%%%% - slower. Where FlowSOM takes seconds, this could take hours to get about the same performance
%Another clustering approach is model-based clustering, the most popular of
%which is the finite gaussian mixture model. To account for irregular shapes and
%the presence of outliers in cytometry data, \cite{lo2009flowclust} developed
%flowClust, which first applies a Box-Cox transformation to the data, and then
%uses a mixture of t-distributions to cluster the transformed data.  The
%expectation-maximization (EM) algorithm \citep{dempster1977maximum} can be used
%to learn the parameters in this model.
%Model-based clustering algorithms are
%among the best performing algorithms used in cytometry data analysis, but they
%can be much slower to train. For instance, flowClust may take hours to train in
%order to get the same performance as FlowSOM when it is only trained for
%seconds.
% 


\subsection{Review: Feature Allocation Models}\label{literature-review}
One of the main inferential goals in analyzing the motivating dataset is to
learn a latent structure of predominant NK cell phenotypes, where cell
phenotype are defined based on distinct expression combinations of the markers.
Specifically, phenotype $k$ is represented by a $J$-dimensional binary vector,
$\bm z_k=(z_{1k}, \ldots, z_{Jk})$, with $J$ denoting the number of markers,
where $z_{jk}$ equals 1 if marker $j$ is expressed in phenotype $k$, and 0
otherwise.  Let $\bZ$ denote a $J \times K$ binary matrix by letting columns
represent $K$ different phenotypes.  Then $2^J$ possible distinct phenotypes
can be constructed for $J$ markers.  One may consider a $J \times 2^J$
binary matrix that includes all possible phenotypes generated by the $J$
markers. But this is computationally infeasible even when $J$ is moderately
large.  Taking a Bayesian approach, we consider a prior probability model over
binary matrices, which in this case represents a library of  phenotypes, to
learn predominant phenotypes from the observed data a posteriori.  These models
are called latent feature allocation models (FAMs). In FAMs, rows and columns
correspond to objects and features, respectively (in the culinary metaphor of
FAMs, customers and dishes, respectively; and in our applications, markers and
phenotypes, respectively). Similar to our construction of phenotypes,
$z_{jk}=1$ corresponds to object $j$ possessing feature $k$.  Conversely,
$z_{jk}=0$ corresponds to object $j$ not possessing feature $k$.  One popular
model for binary feature matrices of this type is the Indian buffet process
(IBP), a Bayesian nonparametric distribution over $\bZ$ with an unbounded
number of latent features, proposed by \citet{griffiths2011indian}.  They
construct the IBP by considering the finite feature allocation model and taking
the limit with respect to the number of features. Concretely, for a given
$K$,
\begin{align}
\begin{split}
v_k \mid \alpha &\sim \text{Beta}(\alpha/K, 1),~ k=1, \ldots, K \\
z_{jk} \mid \pi_k &\sim \text{Bernoulli}(v_k),~ k=1, \ldots, K~\mbox{ and }
j=1, \ldots, J. \\
\end{split}
\label{eq:ibp}
\end{align}
The marginal limiting distribution of $\Z$ defines an IBP as $K \rightarrow
\infty$ and after dropping all columns with all 0's. That is,  $Z \sim
\text{IBP}(\alpha)$, for a positive real $\alpha$.  Under the IBP, each row
has an expected row sum of $\alpha$.  It can be shown that the number of
non-zero columns in $Z$ has a Poisson distribution with mean $\alpha
\sum_{j=1}^J j^{-1}$. A prior distribution can be placed on $\alpha$ to
reflect uncertainty of the number of latent features. A gamma prior is popular
for $\alpha$ due to its conjugacy.

Much theoretical work for the IBP has been generated in recent years.
\cite{teh2007stick} represented the IBP using the stick-breaking construction
similar to the stick-breaking representation of the Dirichlet process (DP).
\cite{williamson2010dependent} developed a dependent IBP (dIBP) to induce
correlations between objects and to model multiple possibly dependent $\Z$'s.
\cite{broderick2015combinatorial} first coined the term ``feature allocation
model". They developed theory for an exchangeable feature probability function
for certain feature allocation models, just as the class of probability
distributions over partitions of a dataset has been characterized through
exchangeable partition probability functions. Under their framework, many other
extensions of the IBP can be proposed.  \cite{broderick2013feature} developed
the beta-negative binomial process for admixtures, where observations are
represented multiple times across several latent features. This is an
extension of the IBP, where infinite-dimensional priors are proposed for
vectors of counts. They develop some computationally efficient algorithms that
rely on Gibbs sampling for posterior sampling. They applied their methods in
some simulation studies involving topic modeling and computer vision.


% TODO
%{\tt please include more. for example, XY's JASA paper develops a fast
%computational method for feature allocation models.  It is something that we
%need to know.}


The IBP as a prior distribution in FAMs has been successfully applied in
diverse areas. \cite{lee2015bayesian} modeled tumor-sample heterogeneity
through a finite IBP using DNA sequencing data.  They used $\bZ$ to describe
latent haplotypes. A prior distribution is placed on the number of subclones.
These parameters are learned jointly through MCMC.  Building on this work,
\cite{xu2015mad} proposed a general class of feature allocation model for
exponential family sampling distributions for modeling tumor heterogeneity.
They note that a computational challenge in sampling from the joint posterior
in such models involves implementing reversible jump MCMC
\citep{green1995reversible} for transdimensional moves. They avoid this by
proposing an MAP-based small-variance asymptotic approximation for any
exponential family likelihood with an IBP feature allocation prior to learn the
feature allocation matrix. The learned feature allocation matrix is then used
to fix the dimensions of a subsequent MCMC conditioned on the number of
features estimated. This method is orders magnitudes faster than
reversible-jump implementations.  \cite{sengupta2014bayclone} and
\cite{lee2016bayesian} proposed a categorical variant of the IBP for
tumor-heterogeneity modeling so that the feature allocation matrix may contain
integer values beyond binary values.  They demonstrated how to obtain posterior
estimates for the feature allocation matrix. They also developed a
computational method to model a random number of features so as to avoid
reversible-jump.

%All these works provide theoretically foundation to our proposed methodology.


\subsection{Proposed Projects}
We propose the following projects to study NK cell phenotypes using mass
cytometry data. 
\begin{itemize}
\item \underline{Project 1:}
We first develop a model to study the composition of cell populations in
multiple samples.  The model directly characterizes latent cell phenotypes with
an IBP prior and clusters individual cells based on identified cell types.  The
model also includes a mechanism for imputing missing observations to account
for missing marker-expression data missing not at random. We demonstrate the
developed model with simulation studies and an analysis of a real cord-blood
dataset.

\item \underline{Project 2:}
Building upon Project 1, we extend our model so as to compare the composition
of the NK cell populations present in cord blood samples and samples taken from
healthy subjects.  We develop a repulsive FAM (rep-FAM) that discourages cell
phenotypes that are similar, and replace the IBP prior distribution with a
rep-FAM prior to obtain a parsimonious representation of the underlying cell
population structures in different samples. We examine the properties of the
proposed rep-FAM and compare them to those of the IBP.  Results from a
simulation study highlighting the key differences between an IBP and a rep-FAM
are presented. An analysis based on a real dataset will be performed.

\item \underline{Project 3:}
We desire to study the change in the abundance of cell phenotypes in patients'
blood samples collected over time. To this end, we will propose a FAM with a
regression to model associations between time and cell type abundances.
Simulation studies and an analysis based on longitudinal data from patients
will be conducted.

\end{itemize} 
The remainder of the document is organized as follows.
\S~\ref{sec:proj1} to \S~\ref{sec:proj3} describe the proposed projects.
\S~\ref{sec:time} discusses a plan to progress the projects.  
Appendix A contains details for posterior computations in Project 1.



\section{Project 1: Bayesian Feature Allocation Model for Heterogeneous Cell Populations}\label{sec:proj1}
\subsection{Introduction}

In this project, we develop a Bayesian FAM, embedded with clustering
capabilities to characterize underlying cell repertoire structures in mass
cytometry data.  Samples in cytometry data consist of tens of thousands of
cells and expression levels of a set of markers are recorded for individual
cells. Large and small observed expression levels may imply expression and
non-expression of the markers, respectively.  A phenotype is defined by its
unique subset of expressed markers and a repertoire in a sample can be
described as a collection of cells possessing different phenotypes.  One
primary research goal is to characterize underlying cell phenotypes in samples
based on observed expression levels and differentiate the samples based on the
identified phenotypes.  Many of the existing methods proposed to analyze
cytometry data use clustering approaches to identify cell subpopulations based
on their marker-expression levels.  They often focus on producing point
estimates of inferred subpopulations, convenient two-dimensional visualizations
of multivariate expression data, and computational efficiency.  While
encouraging, many existing methods fail to provide direct inference on latent
cell types.  Under the clustering methods, cells having the same set of
expressed markers, but different observed expression levels due to technical
variability in an experiment, can be grouped into different clusters.  That is,
cells in different clusters can be characterized as one cell phenotype.  Most
of them are also algorithmic methods and do not produce uncertainty
quantification for the learned clusters and their abundances in samples.  To
address this challenge in characterizing underlying cell repertoire structures,
we use a IBP, one of the most popular FAMs and directly model expression
patterns of latent cell types.  Individual cells in a sample possess cell types
and the distribution of cell types differ in samples. In other words, individual
cells will be connected to identified phenotypes via clustering, with
cluster probabilities varying between samples.  We further model observed
marker expression levels with flexible mixture models to effectively
accommodate variability in expression levels within cells having a cell type.
We will also address the challenge of analyzing cytometry data containing data
missing not at random.  When a marker in a cell is not expressed, cytometry
devices may not register a signal and fail to record expression levels,
yielding missing values.  \cite{franks2016non} provide a brief overview of
typical approaches to imputing data missing not at random, including a
computationally efficient method and intuitive model representation (Tukey's
representation) based only on the observed data.  In our application, the
parameters are entangled with the missingness of the data.  We model missing
data through a selection factorization representation
\citep{rubin1974characterizing} and incorporate missing data into the inference on latent cell repertoire structures.

% , rather than through Tukey's representation. 


In the remainder of the section, we will present the proposed statistical model
in \S~\ref{prob-model}, simulation studies in \S~\ref{sec:CB-sim}, an analysis
of real mass cytometry data in \S~\ref{sec:CB-real}, and some concluding remarks
in \S~\ref{sec:CB-conc}.


%Each sample consists of tens of thousands of cells and
%records expression levels for 32 NK-cell markers. High marker expression levels
%correspond to the expression of that marker, while low marker expression levels  correspond to non-expression. 

%For a given cell, the expression of certain markers corresponds to a phenotype.
%We are interested in identifying phenotypes that occur frequently within each
%sample. This is important to practitioners because NK-cell diversity is known
%to be affect immunity against infectious diseases. 

% We therefore
%propose a fully Bayesian model to model marker expression levels with a
%flexible mixture model, and the latent cell type structure with a latent
%feature allocation model.

%we analyze marker expression data from a CyTOF analysis of
%patient blood samples. 
% We will provide results to a simulation study and an analysis of real cytometry
%data.

% TODO. Done
%{\tt include some references on missing value modeling. Alex's paper and
%Rubin's old papers.}  



\subsection{Probability Model}\label{prob-model}
\subsubsection{Sampling Model} 

$I$ samples are taken from subjects, $i = 1,2,...,I$. Sample $i$ consists
of $N_i$ cells, $n=1, \ldots, N_i$ and for each cell, expression levels of
$J$ markers are measured. Let $\tilde{y}_{inj} \in \mathbb{R}^+$ represent
the raw measurement of an expression level of marker $j$ of cell $n$ in
sample $i$. Let $c_{ij}$ denote the ``cutoff'' for marker $j$ in sample
$i$. A marker of a cell is likely to be expressed if its observed expression
level is greater than the cutoff. A value of $\tilde{y}_{inj}$ below the cutoff
may imply that marker $j$ is not expressed in cell $n$ of sample $i$. 
These cutoff values are computed by cytometry devices and may vary by sample
due to noise in the environment.  We consider the logarithm transformation
after scaling $\tilde{y}_{inj}$ by
$c_{ij}$, 
$$
y_{inj}=\log\p{\frac{\tilde{y}_{inj}}{c_{ij}}} \in \mathbb{R}.
$$
Due to the transformation, a value above (below) 0 is likely to represent
(non-) expression. For some $(i, n, j)$, $\tilde{y}_{inj}$ is missing due to
experimental artifacts and we introduce a binary indicator, 
$$
m_{inj} =
\begin{cases}
  0, & \text{if $\tilde{y}_{inj}$ is observed,} \\
  1, & \text{if $\tilde{y}_{inj}$ is missing.}
\end{cases}
$$

%That is, $m_{inj}=1$ indicates that the expression level of marker $j$ of cell $n$ in sample $i$ is missing.

%\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
%\tightlist
%\item
%  The data have infinite support.
%\item
%  $y_{inj} = 0$ has a special meaning, which is that the data take on
%  the same value as the cutoff. Consequently, $y_{inj} > 0$ means that
%  the data take on values greater than the cutoff, etc.
%\item
%  $y_{inj}$ for which $\tilde y_{inj} = 0$ are regarded as missing,
%  and is to be imputed.
%\end{enumerate}

%\newpage


We assume that a sample has heterogeneous cell populations having $K$ different
phenotypes.  The phenotypes are not directly observable and we introduce latent
phenotype indicators $\lambda_{in} \in \{1, \ldots, K\}$, for cell $n$ in
sample $i$, $i=1, \ldots, I$ and $n=1, \ldots, N_i$.  The event
$\lambda_{in}=k$, for $k=1, \ldots, K$, represents that cell $n$ in sample $i$
possesses phenotype $k$.  The cell phenotypes are defined by columns of a $J
\times K$ binary matrix $\Z$. The element $z_{j, k} \in \{0, 1\}$
indicates whether marker $j$ is expressed in cell phenotype $k$ or not. The
event $z_{jk}=0$ represents that marker $j$ is not expressed for phenotype
$k$, and $z_{jk}=1$ for expression. We let $\Z$ and $\lambda_{in}$ be random
quantities. Modeling details will be discussed later.  Given $z_{j,
\lambda_{in}} \in \{0, 1\}$, we assume a mixture of normals for $y_{inj}$,
%
\begin{align}
y_{inj} \mid \bet_{ij}, \bmu^\star, \bsig^{2 \star}_{i} \ind
\begin{cases}
  \sum_{\ell=1}^{L^0} \eta^0_{ij\ell}~
    \text{Normal}(\mu^\star_{0\ell},
                  \sigma^{2}_{i}), &\mbox{if $z_{j,\lambda_{in}}=0$},\\
  \sum_{\ell=1}^{L^1} \eta^1_{ij\ell}~
    \text{Normal}(\mu^\star_{1\ell},
                  \sigma^{2}_{i}), &\mbox{if $z_{j,\lambda_{in}}=1$},\\
\end{cases} \label{eq:y-mix}
\end{align}
where the number of mixture components $L^0$ and $L^1$ are fixed.  The
vectors $\bet^0_{ij}$ and $\bet^1_{ij}$ are mixture weights with
$\sum_{\ell=1}^{L^0} \eta^0_{ij\ell}=\sum_{\ell=1}^{L^1}\eta^1_{ij\ell}=1$,
where $0 < \eta^1_{ij\ell} < 1$ and $0 < \eta^0_{ij\ell} < 1$.  In
\eqref{eq:y-mix}, $\bmu^\star_0$ and $\bmu^\star_1$ are common for all samples
and markers but $\bsig^{2}$ isindexed by sample $i$ to account for sample
specific variability. Sample and marker specific mixture weight vectors
$\bet^0_{ij}$ and $\bet^1_{ij}$ allow markers in samples to have different
distributions. The mixture model can thus flexibly capture various features
in data. For computational convenience, we introduce mixture component
indicators $\gamma_{inj}$ for $y_{inj}$. Given $\lambda_{in}=k$, we define
$\gamma_{inj}$ for $i=1,\ldots, I$, $n=1, \ldots, N_i$ and $j=1,
\ldots, J$, by
\begin{eqnarray}
P(\gamma_{inj} = \ell \mid \lin=k)=\eta^{z_{jk}}_{ij\ell}, \mbox{ where }~ \ell \in \{1,\ldots, L^{z_{jk}}\}. \label{eq:gam}
\end{eqnarray}
Given $\lambda_{in}=k$ and $\gamma_{inj}=\ell$, we assume a normal
distribution for $y_{inj}$; for $i=1, \ldots, I$,
$n=1, \ldots, N_i$ and $j=1, \ldots, J$,
\begin{align}
  y_{inj} \mid \mu_{inj}, \sigma^2_{inj} &\ind \text{Normal}(\mu_{inj},
  \sigma^2_{i}), \label{eq:y-gam}
\end{align}
where $\mu_{inj} = \mu^\star_{z_{j,k},\ell}$. After marginalizing over
$\gamma_{inj}$, the model in \eqref{eq:y-gam} and \eqref{eq:gam} is
equivalent to the model in \eqref{eq:y-mix}.

We next build a model for the missingness mechanism.  To build the mechanism,
we incorporate information provided by a subject scientist that a marker
expression level is recorded as ``missing'' when a maker in a cell has a very
weak signal, strongly implying that the marker is not expressed.  We take an
empirical approach by assuming that the distribution of the values with
$m_{inj}=1$ is similar to the distribution of observed $y$ below 0. We then let
the probability of $y$ being missing depend on its unobserved value of $y$.
% and assume   % use observed values of $y$ to elicit the probability of $y$
% being missing, $\Prob(m_{inj}=1 \mid y_{inj})$ as a function of $y$.  %In
% addition, we will impose the restriction that extremely low
% expression values have low prior probability. This ensures that parameters in
% the sampling density will not be unnecessarily inflated.
%
Given
$y_{inj}$, we consider a selection function for $m_{inj}$ for
$i=1, \ldots, I$, $n=1, \ldots, N_i$ and $j=1, \ldots, J$,
\begin{align}
  m_{inj} \mid p_{inj} &\ind \Bern(p_{inj}) \label{eq:missing} \\
  \logit(p_{inj}) &= \beta_{0i} - \beta_{1i} \cdot y_{inj} \\
\end{align}
where $\beta_{0i} \in \mathbb{R}$, and $\beta_{1i} > 0$.
% Figure \ref{fig:prob-miss-eg} shows an example missing mechanism. We design
% the missing mechanism to have a peak in the middle to discourage missing
% values from being imputed as either extremely large or extremely small
% values. This helps to control the size of the scale parameter in the mixture
% of Normalsused in the data density.
Note that the assumptions for the distribution of the unobserved data are
untestable. However, we can incorporate input from biologists through
informed prior specifications. Prior uncertainty can then be directly
propagated to the posterior distribution for the missing mechanism.
% TODO: Should we just use strong priors?

% \begin{figure}[th!]
% \begin{center}
% \includegraphics[scale=.5]{img/prob_miss_example.pdf}
% \caption{Example missing mechanism. The blue points serve as guides in
% determining a missing mechanism. Values for $\beta$ and $c$ can be solved for
% through a system of equations.}
% \label{fig:prob-miss-eg}
% \end{center}
% \end{figure}


\subsubsection{Priors}\label{priors}
\paragraph*{Latent cell phenotypes}  Recall that we characterize cell phenotypes with a $J\times K$ binary matrix $\Z =\{z_{jk}\}$.  Following \citet{williamson2010dependent}, we assume
\begin{eqnarray*}
  v_k \mid \alpha &\iid& \text{Beta}(\alpha/K, 1),~ k=1, \ldots, K, \\
  \h_k &\iid& \text{Normal}_J(\bm{0}, \Gamma), \\ 
  z_{jk} \mid h_{jk}, v_k &=& \mathbb{I}\left\{ \Phi(h_{jk} \mid 0,
  \Gamma_{jj}) < v_k \right\},
\end{eqnarray*}
where $\Phi(h \mid m, s)$ is the cumulative distribution function of the normal
distribution with mean $m$ and variance $s$, and $\mathbb{I}(\cdot)$ is an
indicator function having a value of 1 if $\Phi(h_{jk} \mid 0, \Gamma_{jj}) <
v_k$, and 0, otherwise.  As $K \rightarrow \infty$, the limiting distribution of
$Z$ is the IBP \citep{griffiths2011indian}.  Interactions between $J$ markers
in phenotypes can be modeled through $\Gamma$.  Due to the multivariate probit
construction for $\Z$, $\Gamma$ is not identifiable and it is common to
restrict $\Gamma$ to be a correlation matrix. Prior distributions for
correlation matrices have been proposed to handle such cases. Jointly uniform
and marginally uniform prior distributions have been identified by
\cite{barnard2000modeling} for correlation matrices. \cite{box2011bayesian}
have noted that the Jeffreys' prior for correlation matrices is $p(\Gamma)
\propto \abs{\Gamma}^{-(J+1)/2}$.  \cite{zhang2006sampling} presents more
generalized and flexible priors which can be reduced to the two previous priors
as special cases.
%
We let $\alpha \sim \text{Gamma}(a_\alpha, b_\alpha)$ with mean $a_\alpha/b_\alpha$.  

The $K$ cell phenotypes are common in all samples but the relative weights vary
across samples. Let $w_{ik}$ denote an abundance level of phenotype $k$ in
sample $i$.  We assume independent Dirichlet priors for $\bw_i=(w_{i1},
\ldots, w_{iK})$ given $K$, $\bw_{i} \mid K \iid \Dir_K(d/K)$. For the latent
cell phenotype indicators, we let $p(\lin=k \mid \bm \bw_i) = w_{ik}$.

\paragraph*{Parameters in the Mixture for $y$}
In \eqref{eq:y-mix}, normal mixture models are assumed for $y_{inj}$. The mean
expression level of marker $j$ of sample $i$ in cell $n$ is determined by its
phenotype $\lambda_{in}$.  In particular, if the marker is not expressed in the
cell type (i.e. $z_{j \lambda_{in}}=0$), its mean expression level is below the
cutoff, that is, a negative value.  If the marker is expressed (i.e. $z_{j
\lambda_{in}}=1$), the expression level of marker $j$ takes a positive value.
Recall that $\mus_{0\ell}$, $\ell=1, \ldots, L^0$ are mixture locations for
$z_{j \lambda_{in}}=0$ and $\mus_{1\ell}$, $\ell=1, \ldots, L^1$ for $z_{j
\lambda_{in}}=1$.  We assume 
\begin{align*}
\mus_{0,1} \mid \psi_0, \tau^2_0 &\iid \text{TruncatedNormal}(\psi_0, \tau^2_0, -\infty, \mus_{0,2}) \\
\mus_{0,L^0} \mid \psi_0, \tau^2_0 &\iid \text{TruncatedNormal}(\psi_0, \tau^2_0, \mus_{0,L^0-1}, 0) \\
\\
\mus_{1,1} \mid \psi_1, \tau^2_1 &\iid \text{TruncatedNormal}(\psi_1, \tau^2_1, 0, \mus_{1,2}) \\
\mus_{1,L^1} \mid \psi_1, \tau^2_1 &\iid \text{TruncatedNormal}(\psi_1, \tau^2_1, \mus_{1,L^1-1}, \infty) \\
\\
\mus_{z,L^z} \mid \psi_z, \tau^2_z &\iid \text{TruncatedNormal}(\psi_z, \tau^2_z, \mus_{z,\ell-1}, \mus_{z,\ell+1}), ~~~ \ell \in \bc{2,...,L^z - 1}, \\
\end{align*}
where $\TN(m, s^2, a, b)$ denotes the normal distribution. For the variances
$\sigma^2_i$, we let, for $i=1, \ldots, I$,
\begin{align*}
\sigma^2_{i} &\ind \IG(a_\sigma, b_\sigma) \\
\end{align*}
%We also assume $s_i \iid \text{Gamma}(a_s, b_s)$, $i \in \bc{1,...,I}$, with
%mean $a_s/b_s$.
Lastly, we consider a model for the mixture weights $\bm\eta^0_{ij}$ and
$\bm\eta^1_{ij}$. To flexibly model the distribution of $y_{inj}$, we assume
for a marker $j$ in a sample $i$, that $y_{inj}$ has two sets of weights --
one for each value of $z \in \bc{0,1}$. That is, $\bm\eta^0_{ij}$ and
$\bm\eta^1_{ij}$, for each $(i, j)$. So for $i=1,\ldots, I$, $n=1, \ldots,
N_i$ and $j=1, \ldots, J$,
\begin{align*}
\bm\eta^0_{ij} &\iid \Dir_{L^0}(a_{\eta^0}/L^0), \\
\bm\eta^1_{ij} &\iid \Dir_{L^1}(a_{\eta^1}/L^1). 
\end{align*}


\paragraph*{Parameters for Missingness Mechanism}
A prior distribution over the missing mechanism can be specified through
placing priors on the parameters $\beta_{0i}$ and $\beta_{1i}$. 
%
We assume that $\beta_{0i} \iid \N(m_{\beta_0}, s^2_{\beta_0})$ and $\beta_{1i}
\iid \text{Gamma}(\text{shape}=a_{\beta_1}, \text{rate}=b_{\beta_1})$,
 $i=1, \ldots, I$.  We use data to
specify prior means for $\beta_{0i}$ and $\beta_{1i}$.
We let the prior variances for $\beta_{0i}$ and $\beta_{1i}$ be small to induce
informative priors. One way of determining priors for the parameters in the
missing mechanism is described in detail in the derivation of the full
conditionals for $\beta$ in Appendix A.


\subsubsection{Posterior Computation}\label{sampling-via-mcmc}
Let $\btheta=\bc{\bZ, \bw, \bm \mu^\star_0, \bm \mu^\star_1, \bm \sigma^2,
\bm \eta^0, \bm \eta^1, \bm \lambda, \bm \gamma, \bm v, \bm
h, \bm \beta_0, \bm \beta_1, \alpha}$ represent all random parameters.  Let
$\y$ and $\m$ denote $y_{inj}$ and $m_{inj}$ for all $(i,n,j)$, respectively.
The joint posterior distribution is 
\begin{align*}
p(\btheta \mid \y, \m) &\propto 
p(\btheta) \prod_{i,n,j} p(m_{inj} \mid y_{inj}, \btheta) p(y_{inj} \mid \btheta) \nonumber\\
&=  
p(\btheta)
\prod_{i,n,j} \left[
  p_{inj}^{m_{inj}} (1-p_{inj})^{1-m_{inj}} \times 
   \frac{1}{\sqrt{2\pi\sigma^2_{i}}} \exp\bc{-\frac{(y_{inj}-\mu_{inj})^2}{2\sigma^2_{i}}}
\right].
\end{align*}
%The marginal density for $y_{i,n,j}$ after integrating out $\lambda$ and
%$\gamma$ is \begin{align} p(y_{inj} \mid \btheta) = \sum_{k=1}^K W_{ik}
%\sum_{\ell=1}^{L^{Z_{jk}}} \eta^{Z_{jk}}_{ijl} \cdot \N(y_{inj} \mid
%\mu^\star_{Z_{jk}, \ell}, {\sigma^2}^\star_{i,Z_{jk},\ell}).  \end{align}
Posterior simulation can be done via Gibbs sampling by repeatedly and
sequentially updating each parameter until convergence. Parameter updates are
made by sampling from its full conditional distribution. Where this cannot be
done conveniently, a Metropolis step can be used.  Details for the posterior
simulation are omitted due to the space limit.  %are described in Appendix A. 


Summarizing the joint posterior distribution $p(\btheta \mid \y, \m)$ is
challenging, especially for $\Z$, which may be susceptible to label switching
problems common in mixture models. Note also that the posterior distributions
of $\Z$ is dependent on those of $\bw$ and $\bm \lambda$. To summarize the
posterior distribution of $(\Z,\bW,\lambda)$ with point estimates, we use a
method based on sequentially-allocated latent structure optimization (SALSO)
\citep{salso} for summarizing random samples over partitions. To summarize
random feature allocation matrices, SALSO first constructs
$A(\bZ)=\{A_{j,j'}\}$, the $J \times J$ pairwise allocation matrix
corresponding to a binary matrix $\bZ$, where  
$$
A_{j,j'} = \sum_{k=1}^K \mathbb{I}(Z_{j,k}=1)\mathbb{I}(Z_{j',k}=1),
~~~\text{for } 1\leq j, j^\prime \leq J,
$$
is the number of features that markers $j$ and $j'$ share. It then uses
constrained optimization to find a point estimate $\hat{\bZ}$ that
minimizes the sum of the element-wise squared distances, 
\begin{eqnarray*}
\text{argmin}_Z\sum_{j=1}^J\sum_{j'=1}^J(A(\bZ)_{j,j'} - \bar{A}_{j,j'})^2
\label{eq:salso}
\end{eqnarray*}
%
where $\hat A$ is the pairwise allocation matrix averaged over all posterior
samples of $Z$.  %Thus in the current application, $A_{j,j'} = \sum_{k=1}^K
%\Ind{Z_{j,k}=1}\Ind{Z_{j',k}=1}$ is the number of times that marker $j$ and
%marker $j'$ share a feature. 
%
We extend SALSO to find point estimates for each sample $i$, $\hat{\bZ}_i$ by
incorporating $\bw_i$. Specifically, we consider the sum of element-wise squared
distances weighted by $\bw_i$.  We use posterior Monte Carlo samples to obtain
posterior point estimates $(\hat{\Z}_i$, $\hat{\bm W}_i)$ and
$\hat{\lambda}_{in}$, for $i=1, \ldots, I$ and $n=1, \ldots, N_i$ as follows.
Suppose we obtain $B$ posterior samples simulated from the posterior
distribution of $\btheta$. For each posterior sample of $\Z$ and $\bw_i$,
we compute a $J \times J$ adjacency matrix, $\bm A_i^{(b)}
=\{A^{(b)}_{i,j,j'}\}$, where 
%
\[
A^{(b)}_{i,j,j'} = \sum_{k=1}^K w^{(b)}_{ik} 
\mathbb{I}\left( z^{(b)}_{jk} = 1\right)
\mathbb{I}\left(z^{(b)}_{j^\prime k} = 1\right), b \in \bc{1,...,B}.
\]
We then compute the mean adjacency matrix $\bar A_i = \sum_{b=1}^B A_i^{(b)} /
B$.  We report a posterior point estimate of $\Z_i$ by choosing
\begin{eqnarray}
\hat{\bm Z}_i = \text{argmin}_{\bm Z} \sum_{j,j'} (A_{i,j,j'}^{(b)} - \bar
A_{i,j,j'})^2).\label{eq:myZ}
\end{eqnarray}
If $\hat{\Z}_i = Z^{(b)}$, then we report the posterior point estimates
$\hat{\bw}_i=\bw_i^{(b)}$ and $\hat{\lambda}_{in}=\lambda_{in}^{(b)}$.
%Note that in our adaptation, we weight
%the adjacency counts by the sample-specific weight for each latent feature.
Equation \eqref{eq:myZ} places greater weight on phenotypes that are more
prevalent in samples, and down-weights phenotypes having small $w_{ik}$ for
$\hat{\bZ}_i$.


%%% sim-study-proj1 %%%
%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t!]
  \begin{center}
\begin{tabular}{c}
\includegraphics[scale=.8]{img/sim/Z_true_all.pdf}
  \end{tabular}
 \end{center}
 \vspace{-0.05in}
\caption{The transpose of $\bZ^\true$ with markers in columns and latent
phenotypes in rows. Black and white represents $z^\true_{jk}=1$ and 0,
respectively. The phenotypes and $\bw^\true_i$ are shown on the left and
right sides of each panel, respectively. The samples share the same $\bZ^\true$ and the phenotypes are arranged in order of
$w_{ik}^\true$ within each sample.}
\label{fig:sim-Z}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Simulation Study}\label{sec:CB-sim}
We conducted a simulation study to evaluate the performance of the proposed
model and compare our model to existing methods.
%\subsubsection{Data Simulation}
To simulate data, we assume the number of markers ($J$) to be 32, the number of
samples ($I$) to be 3, and the number of cells in the samples ($N$) to be
$(300, 200, 100)$.  We let the true number of latent cell types $K^\true=10$.
We specified $\bZ^\true$ and $\bw^\true_i$, for $i=1,2,3$ as follows: We first
simulated $\bZ^\true$ by setting $\bZ^\true_{jk}=1$ with probability 0.6 for
$j=1,...,J$ and $k=1,...,K$. If any column or row in $\bZ^\true$ is a column or
row of only 0's, the entire matrix is re-sampled.
% Simulating W
We then simulated $\bw^\true_i$ from a Dirichlet distribution with parameters
being some permutation of $(1, \ldots,K)$. This encourages the simulated values
in $\bw^\true_i$ to contain large as well as small values.
%
Figure \ref{fig:sim-Z} shows the transpose of $\bZ^\true$ and $\bw^\true_i$ for
the samples. In each panel, the cell types ($\bZ^\true$) are sorted by
$w_{ik}^\true$.  Three and four mixture components were used for non-expressed
and expressed marker expression levels, respectively. That is, $L^{0, \true}=3$
and $L^{1, \true}=4$. We set  $\mu^{\star, \true}_{0} = (-5, -2, -1)$ and
$\mu^{\star, \true}_{1} = (1, 2, 4, 5)$. Values of $\sigma^{2,
\true}_{i}$ are drawn 
from a Uniform(0,~0.3) distribution for all $i$ and $\ell$.
%
We simulated $\bet_{0ij}^\true$ from a Dirichlet distribution with
parameters being some permutation of $(1,...,L^{0,\true})$. Similarly, 
$\bet_{1ij}^\true$ was simulated from a Dirichlet distribution with
parameters being some permutation of $(1,...,L^{1,\true})$.
%
We then simulated latent phenotype indicators $\lambda_{in}^\true$ using
$\bw_i^\true$, and conditionally on $z^\true_{j,\lambda_{in}^\true}$ generated
$y_{inj}$ from the mixture model, $\sum_{\ell=1}^{L^{0,\true}}
\eta^\true_{0ij}\cdot\N(\mu^{\star, \true}_{0\ell}, \sigma^{2,
\true}_{i})$ or $\sum_{\ell=1}^{L^{1,\true}}
\eta^\true_{1ij}\cdot\N(\mu^{\star, \true}_{1\ell}, \sigma^{2,
\true}_{i})$. Finally, let some of the $y_{inj}$
be missing as follows. Simulate a proportion $(p_{ij})$ of values to be missing
for marker $j$ in sample $i$, from a
Uniform$\p{0, \sum_k w^\true_{ik}(1-z^\true_{jk})}$ distribution. Sample
$p_{ij}\times N_i$ cells without replacement with probability proportional to
% TODO. DONE
%{\tt give the function used}.
$$
\begin{cases}
  \text{logistic}\p{4.6 - 0.42(y_{inj}+3)^2}, & \text{if } y_{inj} < -3 \\
  \text{logistic}\p{4.6 - 0.42\sqrt{y_{inj}+3}}, & \text{otherwise,} \\
\end{cases}
$$
%
where $\text{logistic}(x) = (1 + \exp\bc{-x})^{-1}$.
Under the true missingness mechanism, $y$ taking a negative value has a larger
chance to be missing, while $y$ with a positive value has only slight chance of
being missing.  Note that the true mechanism is different from that assumed in
the proposed model. Heatmaps of the simulated $\y$ are shown in the heatmaps
on the top of each panel in Figure \ref{fig:sim-post-Z}.
The $y_{inj}$'s are sorted within a sample according to their posterior
phenotype estimates (will be discussed later). Red, blue and black colors
represent high expression levels, low expression levels, and missing values,
respectively.

%\beginmyfig
%\includegraphics[scale=.3]{img/sim/Y001.png}
%\includegraphics[scale=.3]{img/sim/Y002.png}
%\includegraphics[scale=.3]{img/sim/Y003.png} \\
%\includegraphics[scale=.3]{img/sim/Ysorted001.png}
%\includegraphics[scale=.3]{img/sim/Ysorted002.png}
%\includegraphics[scale=.3]{img/sim/Ysorted003.png} 
%\caption{Heatmaps of simulated $y_{inj}$ with cells in rows and markers in columns.  The values are sorted according to their $\lambda_{in}^\true$.} %  The simulated marker expression data $y$. The upper panel contains
%data for sample 1 (left), sample 2 (middle), and sample 3 (right). The lower
%panel is the same data but with the rows (cells) grouped according to the true
%cell types ($\lambda$).}
%\label{fig:sim-Y}
%\endmyfig
%reference this figure like so: \ref{fig:sim-Y}


%The steps for simulating data is as follows.
%First specify dimensions of the data through $I$ (number of samples), $J$
%(number of markers), and $N_i$ (number of cells in sample $i$). Specify the
%dimensions of the parameters through $K$ (true number of latent cell types),
%$L^0$ (number of mixture components in density for cells not expressing a
%marker), and $L^1$ (number of mixture components in density for cells
%expressing a marker). Then fix the latent cell type matrix $\bZ^\true$
%according to $J$ and $K$. Set values for $\sigma^{2, \true}_{0i\ell}$,
%$\sigma^{2,\true}_{1i\ell}$, $\mu^{\star, \true}_{0\ell}$ and $\mu^{\star,
%\true}_{1\ell}$.  This can be done using empirical values from CB data.
%Simulate $\bw^\true_i$ from a Dirichlet distribution with parameters $a_1,
%\ldots, a_K$. This ensures that $\sum_{k=1}^K \bw^\true_i = 1$.
%Similarly, $\eta^\true_{0ij}$ and $\eta^\true_{1ij}$ can be simulated
%from Dirichlet distributions. Note that $\eta^\true_{0ij}$ is an
%$L^0$-dimensional vector, while $\eta^\true_{0ij}$ is an $L^1$-dimensional
%vector. Using these parameters, simulate $y_{inj}$ according to the sampling
%density. Finally, probabilistically set some of the $y_{inj}$ to be missing.
%This can be done by first predetermining a certain percentage ($p\%$) of the
%data to be missing. This percentage should should be less than $\sum_k
%w^\true_{ik}(1-z^\true_{jk})$ so that truly expressed cells are unlikely to be
%missing, and so as to be consistent with the simulated $W^\true$ and
%$\bZ^\true$. Sample ($N_i\times p\%$) observations of $y_{inj}$ without
%replacement with the probability of missing for $y$ being proportional to some
%predetermined missing mechanism (possibly different from the one used in this
%model). Care should be taken to ensure $y$ with positive values have almost
%zero probability of being missing.

%\textbf{Simulated $\bZ^\true$ and $W^\true$}

%Following this scheme, we generated data comparable to the CB data.  In our
%simulated data we assume 3 samples, each having $J=32$ markers, and each sample
%containing tens of thousands of cells. This size resembles that of the CB data.
%We then simulated $\bZ^\true$ and $W^\true$ with number of columns being $K=10$
%to include a variety of cell types. Figure \ref{fig:sim-Z} shows the simulated
%$\bZ^\true$ with the latent features sorted by $W_i$ for each sample. 


%The data $\y$ are shown in Figure \ref{fig:sim-Y}. The number of cells in each
%sample are $N=(30000, 20000, 10000)$. Note that in the upper panel contains
%marker expression data for sample 1 (left), sample 2 (middle), and sample 3
%(right). The lower panel contains the same data but with the rows grouped by
%the true cell types ($\lambda$).  Red regions represent high expression levels,
%whereas blue regions represent low expression levels. Thus, through this
%visualization, we can observe the true latent cell types that are generating
%the data. Note that in this simulated data set, the white regions represent
%missing data.  Three and four mixture components were used for non-expressed
%and expressed marker expression levels respectively. 


%\subsubsection{Results}
%% TODO: Everything below here is not revised...
To fit the proposed model, we fixed $(K=12, L^0=5,
L^1=5)$. We used the mean of $y_{inj}$  having negative values to specify $c_0$
and let $c_0=-2.5$ and $c_1=10.43$. We fixed $\Gamma=\bI_J$,
$J\times J$ identity matrix for simplification. We specified the remaining fixed
hyperparameters as follows:
%
$a_\alpha=3$ $b_\alpha=2$, $\psi_0=-2$, $\tau^2_0=0.09$, $\psi_1=2$,
$\tau^2_1=0.09$, $a_\sigma=6$, $a_s=0.25$, $b_s=0.5$, $a_{\eta^0}=0.2$,
$a_{\eta^1}=0.2$, $m_{\beta_0}=1.37$, $s^2_{\beta_0}=1$,
$m_{\beta_1}=0.57$, and $s^2_{\beta_1}=0.01$.
%
To run the MCMC simulation, we initialized the parameters as follows; The
missing values of $y_{inj}$ are initialized at $c_0$.  $\lambda_{in}$ is
sampled uniformly from $\bc{1,...,K}$.  $\gamma_{inj}$ is sampled uniformly
from $\bc{1,...,\min(L^0,L^1)}$. $v_k$ is initialized at $1/K$. $h_{jk}$ is
randomly sampled from the standard Normal distribution. $\bZ$ is computed
according to the initialized $h$ and $v$. All other parameters are initialized
at their prior means.  Initial values of $\lambda_{in}$ are used to initialize
$\mu^{\star}_{0\ell}$, $\mu^{\star}_{1\ell}$, $\bZ$ and $\bw_i$.  We then
implemented posterior inference using MCMC simulation over 3,000 iterations,
discarding the first 1,000 iterations as burn-in.  We diagnose convergence and
mixing of the described posterior MCMC simulation using trace plots. We found
no evidence of practical convergence problems. 


%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}[H]
\begin{figure}[th!]
  \begin{center}
  \begin{tabular}{cc}
  \includegraphics[scale=.4]{img/sim/YZ001.png}&
  \includegraphics[scale=.4]{img/sim/YZ002.png}\\
  {\small (a) Sample 1} & {\small(b) Sample 2} \\
  \includegraphics[scale=.4]{img/sim/YZ003.png}&\\
  {\small (c) Sample 3} & \\
  \end{tabular}
  \end{center}
  \vspace{-0.05in}
  \caption{\small[Simulation]  Heatmaps of $y$ for simulated data. Cells and
    markers are in rows and columns, respectively. Each column contains the
    expression levels of a marker for all cells in the sample. High expression
    levels are red, low expression levels are blue, missing values are black.
    Cells are rearranged by the corresponding posterior estimate of their
    phenotype indicator, $\hat{\lambda}_{in}$.  Yellow horizontal lines separate
    cells by different phenotypes.  At the bottom of each panel, the
    transpose of $\hat{\Z}_i$ and $\hat{\bw}_i$ are provided for each sample.
    We include phenotypes having largest $\hat{w}_{ik}$ to explain at least 90\%
    of the cells in a sample.}
\label{fig:sim-post-Z}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%


Figure \ref{fig:sim-post-Z} summarizes the posterior inference for the
simulated data.  The posterior point estimates $\hat{\bZ}_i$ and $\hat{\bw}_i$
are obtained using the method described in \S~\ref{sampling-via-mcmc}.  
%
%provides
%representation of the data $y$ sorted by a point-estimate of their cell types,
%for each sample.  These figures are supplemented by a point-estimate of $\Z$
%and $W$. 
The bottom of each panel illustrates $\hat{\bZ}_i$ with $\hat{\bw}_i$ in
percentages on the right side. Among $K=12$ phenotypes, phenotypes having the
largest $\hat{w}_{ik}$'s that make up more than 90\% of cells are included
in the plots of $\hat{\bZ}_i$. Compared to their truth in Figure~\ref{fig:sim-Z},
$\hat{\bZ}_i$ and $\hat{\bw}_i$ are very close to $\bZ^\true$ and $\bw_i^\true$
for all samples. Note that the phenotype labels do not match in the figures due
to the fact that the model for $\bZ$ is invariant under relabelling of the
phenotypes. For example, phenotype 3 in $\bZ^\true$ has $w^\true_{ik}=23.9\%$
for sample 1.  That phenotype is shown as phenotype 16 in the very bottom of
$\hat{\bZ}_i$ with $\hat{w}_{ik}=20.1\%$.
%Phenotypes with small $w^\true_{ik}$ are not well captured in $\hat{\bZ}_i$.
%For example, cell type 7 ($k=7$) with $w^\true_{1k}=4.5\%$ is not well
%identified.  On the other hand, it is well captured for sample 2 since
%$w^\true_{27}=14.8\%$ in the truth. 
The heatmaps of observed $y$ arranged according to cell phenotype estimates $\hat{\lambda}_{in}$ show
that the expression patterns in $y$ are well explained by $\hat{\bZ}_i$ and
$\hat{\bw}_i$.  The top of each panel has a heatmap of $y$ rearranged by their
$\hat{\lambda}_{in}$, with the colors red, blue, and black for large, small, and
missing values, respectively.  The horizontal yellow lines separate cells based
on $\hat{\lambda}_{in}$.  It shows that the estimated phenotypes capture the
expression patterns of $y$ well. Phenotypes with reasonably large $w_{ik}^\true$ in at least sample are not well estimated.



%vary only rarely by
%small permutations in less common cell types. The cell types in $\Z$ are sorted
%by a point-estimate for $W_i$.  These also resemble $W_i^\true$ but vary
%occasionally from the truth for smaller values of $W_i$. Only the cell types
%that make up the top 90\% of cells are included in Figure \ref{fig:sim-post-Z}.


%\textbf{Posterior Estimate for $\bZ$ and $W$}
%\beginmyfig
%\includegraphics[scale=.3]{img/sim/YZ001.png}
%\includegraphics[scale=.3]{img/sim/YZ002.png}
%\includegraphics[scale=.3]{img/sim/YZ003.png}
%\caption{$y$ sorted by a point-estimate of their cell types ($\lambda$), for
%each sample.  Point-estimates of $\Z$ (sorted by $W_i$) and $W_i$ are provided
%for each sample below each $y_i$.}
%\label{fig:sim-post-Z}
%\endmyfig

%Appendix \ref{sec:sim-pp-observed} contains the posterior predictive of the
%observed simulated data for each sample $i$ and marker $j$. The blue lines are
%the posterior predictives and the grey lines are the observed data density. The
%text in the graphs are the posterior probabilities that the missing values are
%not expressed within each sample $i$ and marker $j$. This quantity should be 1
%because we desire that the missing values should correspond to non-expression.

% TODO
%{\tt TODO.
%\begin{itemize}
%\item as we discussed, include posterior prob that a maker is not expressed if
%  it is missing and posterior distributions of $y_{inj}$ for observed ones for
%  each $(i,j)$. (I have this, just waiting for graphs.)
%\item comparison of posterior predictive distribution to density estimates of
%  observed $y$. (I have this, just waiting for graphs.)
%\item comparison between FlowSOM
%\item sensitivity analysis ($K$ larger than $K^\true$ and smaller than
%  $K^\true$. (I do not have this for smaller $K$...)
%\end{itemize}
%}

%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t!]
\begin{center}
  \begin{tabular}{ccc}
  \includegraphics[scale=.29]{img/FlowSOM/YZ001_FlowSOM_SIM.png}&
  \includegraphics[scale=.29]{img/FlowSOM/YZ002_FlowSOM_SIM.png}&
  \includegraphics[scale=.29]{img/FlowSOM/YZ003_FlowSOM_SIM.png}\\
  {\small (a) Sample 1} & {\small (b) Sample 2} &  {\small (c) Sample 3}\\
  \end{tabular}
  \vspace{-0.05in}
  \caption{\small[FlowSOM for Simulated Data] Heatmaps of $y_{inj}$ sorted by
  the cluster labels estimated by FlowSOM.}
  \label{fig:sim-FlowSOM-Z}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%


We compared our model to FlowSOM as it tends to be fast and performant in a
variety of situations \citep{weber2016comparison}. Since FlowSOM does not
impute missing values, the missing values were first set to be the minimum
value of the observed values in the data. FlowSOM does not account for variability in samples and the three samples were combined for analysis.  Eight
cell clusters are produced and clustering of cells estimated by FlowSOM is
%
summarized in Figure~\ref{fig:sim-FlowSOM-Z}. Recall that FlowSOM uses
similarities in expression levels for clustering instead of combinations of
expression/no expression of the markers. For example, the largest cell cluster
in sample 1 (very bottom of the heatmap) has large variability in $y$. In
particular, cells in the cluster have missing values (black) and large
expression values (red) for some markers.   The cells having the same true cell
phenotypes tend to be in a cluster but their cell clusters do not exactly
correspond to any of the true phenotypes in $\bZ^\true$.
%
In some of our exploratory simulations, FlowSOM and the proposed FAM produce
the same clusters when expression levels of the phenotypes in the simulated
data are equidistant.  This reveals a fundamental difference in our proposed
FAM. We will conduct more simulation studies to further investigate the
performance of the proposed FAM and comparison to the existing models.


% -- FAM directly models the latent
%phenotypes, whereas FlowSOM clusters observations based on some distance
%metric. Therefore, as illustrated, our proposed FAM may perform better at
%discovering latent phenotypes in data that comprises irregularly spaced
%clusters of cells at a computational cost.






% FlowSOM does not jointly analyze
%samples and a sample combining the three simulated samples is used. 
%Specifically, we compared the cell type (cluster) labels generated by the two
%models.
%Let $\hat \lambda_{in}$ be the posterior estimate of the cell type labels
%$\lambda_{in}$ in sample $i$ for cell $n$ in our model.
%One statistic to summarize the accuracy of the computed set of cluster labels
%is the F-score, which is defined as the harmonic mean of precision and recall.
%Specifically,
%$$
%F_1 = \frac{2}{\text{precision}^{-1} + \text{recall}^{-1}},
%$$
%where precision is defined as $\frac{\text{true positives}}{\text{true
%positives} + \text{false positives}}$ and recall is $\frac{\text{true
%positives}}{\text{true positives} + \text{false negatives}}$.  F-scores are
%between 0 and 1, with higher scores being more desirable. In our simulated
%data, we know the true cell type labels, and hence we can compute the F-score.
%But the true cell type labels are not usually known in practice. In such cases,
%the F-score would not be a viable metric for assessing model-fit.  Table
%\ref{tab:fscores} shows the F-scores and the elapsed run-times for FlowSOM and
%our proposed FAM.  We see that the F-score for our model is 1.00, but the
%run-time is orders of magnitudes longer; while the FlowSOM model runs much
%quicker but attains a lower F-score of 0.837. This suggests much room for
%improvement in terms of computational efficiency in our method, which will be
%considered in future research.

% latex table generated in R 3.4.4 by xtable 1.8-2 package
% Thu May 17 17:41:15 2018
%\begin{table}[H]
%\centering
%\begin{tabular}{rrl}
%  \hline
%  & F-score & Elapsed time \\
%  \hline
%  FAM & 100.00\% & 39 hours \\
%  FlowSOM & 99.96\% & 13 seconds \\
%  \hline
%\end{tabular}
%\label{tab:fscores}
%\caption{Comparison of F-score and elapsed time for FlowSOM and our proposed
%FAM. High F-scores and low elapsed times are desirable.}
%\end{table}

%\begin{table}[H]
%\centering
%\input{img/FlowSOM/timings_FlowSOM_vs_SIM.tex}
%\label{tab:fscores}
%\caption{Comparison of F-score and elapsed time for FlowSOM and our proposed
%FAM. High F-scores and low elapsed times are desirable.}
%\end{table}

%In some of our exploratory simulations, FlowSOM and FAM produced the same
%clusters, and hence, yield the same F-score. Notably, this is true when the
%generated clusters in the simulated data are equidistant. This reveals a
%fundamental difference in our proposed FAM -- FAM directly models the latent
%phenotypes, whereas FlowSOM clusters observations based on some distance
%metric. Therefore, as illustrated, our proposed FAM may perform better at
%discovering latent phenotypes in data that comprises irregularly spaced
%clusters of cells at a computational cost.


%{\tt this make our method look really bad. it looks like there is no advantage
%of using our method. can you explain why? or cook some other small simulation
%study where our model works better?  }

%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t!]
\begin{center}
  \begin{tabular}{cc}
  \includegraphics[scale=.4]{img/ksen/YZ001_K5.png}&
  \includegraphics[scale=.4]{img/ksen/YZ001_K10.png}\\
  {\small (a) $K=3$} & {\small (b) $K=10$} \\
  \includegraphics[scale=.4]{img/ksen/YZ001_K20.png}& \\
  {\small (c) $K=20$} &\\
  \end{tabular}
  \vspace{-0.05in}
  \caption{\small[Sensitivity analysis for $K$] Posterior estimates of
    $\hat{\bZ}_i$ and heatmaps of $y_{inj}$ rearranged by latent cell phenotype
    estimates for sample 1 ($i=1)$. Data is simulated with $K^\true=10$ and the
    model was fit with three different values of $K$, $K=3$, 10 and 20 in
    (a)-(c), respectively.  For $\hat{\bZ}$ we include phenotypes having the
    largest $\hat{w}_{ik}$ to explain at least 90\% of the cells in a sample. }
  \label{fig:ksen-post-Z}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%


\paragraph*{Sensitivity to Specified $K$}
The value of $K$ determines the dimensions of the latent feature matrix $\bZ$
and cell phenotype abundance vectors $\bw_i$.  To assess the FAMs sensitivity
to the specification of $K$, we performed a simulation study keeping most of
the simulation set-up described previously, except with the number of cells
being $N=(1500, 600, 300)$. We fit the proposed model with different
specifications of $K$, with $K=5, 10, \text{ and } 20$. Recall that
$K^\true=10$ is used to simulate data.  Figure \ref{fig:ksen-post-Z} summarizes
the posterior estimates of $\bZ_i$ and displays $y_{inj}$ rearranged by their
estimated phenotypes for sample 1 ($i=1$) with the three values of $K$. It is
clear from panel (a) that when $K=3$ (less than $K^\true$), the model
compromises the true cell population structure and cells of different true
phenotypes are forced to have those phenotype estimates. In particular, cells
in estimated phenotype 5 show large variability in $y_{inj}$.  On the other
hand, from panels (b) where $K=K^\true=10$ and (c) where $K=20 \geq K^\true$,
the predominant phenotypes are well recovered. 
% F-scores:
%The F-scores were computed for each of the models using the posterior estimate
%for $\lambda$ as 0.607, 0.947, and 0.932 respectively for $K=5$, $K=10$, and
%$K=20$. 
When $K$ is larger than $K^\true$, not only are the predominant cell phenotypes
recoverable in $\bZ$, but the model performance does not suffer critically
either. We therefore recommend using a reasonably large $K$ in a real data
analysis.

%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[th!]
\begin{center}
  \begin{tabular}{cc}
  \includegraphics[scale=.4]{img/cb/YZ001.png}&
  \includegraphics[scale=.4]{img/cb/YZ002.png}\\
  (a) Sample 1 & (b) Sample 2 \\
  \includegraphics[scale=.4]{img/cb/YZ003.png} &\\
  (c) Sample 3 & \\
  \end{tabular}
\end{center}
\vspace{-0.05in}
\caption{[CB Data]  Heatmaps of $y$ for the samples. Cells and markers are in
rows and columns, respectively. Each column contains the expression levels of
a marker for all cells in the sample. High expression levels are red, low
expression levels are blue, missing values are black.   Cells are rearranged
by their posterior estimate of phenotype indicator, $\hat{\lambda}_{in}$.
Horizontal lines separate cells in different estimated phenotypes.
At the bottom of each panel, the transpose of $\hat{\Z}_i$
and $\hat{\bw}_i$ are provided for each sample. We include phenotypes having
largest $\hat{w}_{ik}$ to explain at least 90\% of the cells in a sample.}
\label{fig:cb-post-Z}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%


%does k
%But it should be noted that
%the estimated $\bZ$ matrix for each sample contains different cell types.
%Moreover, within each sample, the cell types may be repeated or vary by only
%one marker. We would like the learned cell types to be different rather than
%very similar (or repeated). We can impose this constraint using a repulsive
%mixture prior \citep{petralia2012repulsive} for the cell types. This serves as
%the motivation for Project 2, where we impose more structure in the prior 
%specification of the latent feature matrix $\bZ$ so that similar cell types
%appearing in the matrix is discouraged, while distinctness is encouraged.

%Finally, it can be seen that the different samples consist of different
%sub-populations of NK-cells though some cell types are shared across samples.
%Hence, we see that information can be borrowed across multiple samples to
%discover common cell types across samples.

%\textbf{Assessing Model Fit}

%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[th!]
\begin{center}
  \begin{tabular}{cc}
  \includegraphics[scale=.4]{img/cb/pp_obs_i1_j1.pdf}&
  \includegraphics[scale=.4]{img/cb/pp_obs_i1_j2.pdf}\\
  {\small (a) Sample 1, marker 1} & {\small (b) Sample 1, marker 2} \\
  \includegraphics[scale=.4]{img/cb/pp_obs_i2_j22.pdf}&
  \includegraphics[scale=.4]{img/cb/pp_obs_i3_j19.pdf}\\
  {\small (c) Sample 2, marker 22} & {\small (d) Sample 3, marker 19} \\
  \end{tabular}
\end{center}
\vspace{-0.05in}
\caption{[CB Data] Comparison of posterior predictive distribution of $y_{inj}$
with $m_{inj}=0$ (observed data, blue) to their empirical distributions of
observed data (grey) for some selected $(i,j)$.  An estimate of posterior
probabilities of non-expression $\Prob(z_{j, \lambda_{in}}=0 \mid \by, \bm)$
averaged in a sample for missing $y$ is shown in each panel.}
\label{fig:cb-pp-obs-some}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[th!]
\begin{center}
% \begin{tabular}{c}
   % FIXME%
%  \includegraphics[scale=0.45]{img/cb/miss_mech_posterior.pdf}& %Currently beta is fixed
  \includegraphics[scale=0.45]{img/cb/pz0_missy.pdf}%\\
% (a) Posterior mean of $p_{inj}$ & (b) Histogram of $\hat{q}_{ij}$ \\
% \end{tabular}
  \caption{ %(a) The posterior mean of probability $p_{inj}$ of missing with
    %95\% credible interval for the three samples (red).  The blue curve
    %represents the prior mean of $p_{inj}$.   
    %(b) 
    Histogram of posterior
    probabilities $\hat{q}_{ij}$ of non-expression for missing for all $(i,j)$.
    The peak at the value of 1 suggests that most of the
    time, a marker is estimated as no expression if its expression level is
    missing.}
  \label{fig:hist-pz0-missy}
\end{center}
\end{figure}



%%% cb-proj1 %%%
\subsection{Cord Blood Data}\label{sec:CB-real}
We fit the proposed model to a real data set comprising cord blood samples from
three patients ($I=3$), with the number of cells $N=(41474, 10454, 5177)$, for
$J=32$ markers. The heatmaps in Figure \ref{fig:cb-post-Z} illustrate the
observed expression levels $y_{inj}$.  Markers and cells are in columns and
rows, respectively. 
% 
%The values are rescaled for better illustration.
%
Red, blue and black colors represent high expression levels, low expression
levels and missing values, respectively.  From the figure, the expression
levels of some markers are missing in most cells. For instance, marker CD25
(column 9) is missing in more than 80\% of cells in all samples.
%{\tt give a short summary about \% of missing values for $(i,j)$}
In each sample, the proportion of missing values in each marker can be as low
as 0.1\% and as high as 80\%.  Median proportions of missing values across all
markers are 22\%, 17\% and 18\% in the samples, respectively.

%%% TODO for talk: Use Random beta %%%
To carry out posterior inference, we specified prior distributions using
hyperparameters similar to those in the simulation studies. As a preliminary
analysis, we fixed $\beta_{0i}$ and $\beta_{1i}$, parameters for the imputation
of missing values. 2000 samples from the posterior distribution were obtained
after a burn-in period of 1000 iterations. The results are summarized in Figure
\ref{fig:cb-post-Z}.  Point estimates for $\hat{\bZ}_i$ and $\hat{\bw}_i$ are
obtained using the method in \S~\ref{sampling-via-mcmc}.
% illustrated at the bottom of each panel.   
Plots of $\hat{\bZ}_i$ are given with the corresponding $\hat{\bw}_i$ at the
bottom of the panels.  From the estimated weights $(\hat{\bw}_i)$, the samples
have some common phenotypes such as phenotypes 17, 15 and 18.
$\hat{\bw}_i$ also shows heterogeneity across samples.  For example, phenotype
17 comprises 29.7\%, 48.8\%, and 45.2\% of cells for samples 1, 2 and 3,
respectively.
%
Similarly, phenotype 16 is most prevalent in sample 1.  $\hat{w}_{ik}$ for the
phenotype is 29.7\%, 10.2\%, and 9.4\% in samples 1, 2 and 3, respectively.
%
%Phenotypes 7 and 18 are different dominantly for expression of markers 17, 18
%and 19 corresponding to EOMES, GrA (granzyme A) and GrB (granzyme B).
Also, note that some phenotypes are similar. For example, phenotypes 8 and
12 in panel (a).  A possible reason for this is that independence across
columns under the prior model for $\bZ$ allows identical columns with positive
probability.  For the heatmaps on the top of the panels, $y_{inj}$ are sorted
by a posterior estimate $\hat{\lambda}_{in}$ of their cell phenotypes. The
horizontal dotted lines separate cells using $\hat{\lambda}_{in}$.  From the
heatmaps, the cells having a phenotype have similar expression patterns,
implying that the model provides reasonable estimates of underlying cell
subpopulations.

To assess model fit, we compare the posterior predictive distribution of
$y_{inj}$ with $m_{inj}=0$ to the distribution of observed data. Figure
\ref{fig:cb-pp-obs-some} illustrates the posterior predictive distributions
(blue) and empirical distribution estimates of the observed data $y_{inj}$
(grey) for some selected $(i,j)$.  For the four cases, 0.32\%, 70.8\%, 8.78\%
and 4.19\% of $y_{inj}$ are missing, respectively.   The model reasonably well
fits for the observed data, especially for the three cases in panels (a), (c),
and (d).  For the case in panel (b), the fit is deteriorated. Some bigger
discrepancy between the posterior predictive estimates and the empirical
estimate is observed for negative values of $y_{inj}$.  It is  possibly because
the proportion of missing data is extremely high (70\%).  
%The plot also shows a posterior probability that a
%marker is expressed for phenotypes possessed by cells in a sample,
%$\hat{q}_1=\Prob(z_{j \lambda_{in}}=1 \mid \by, \bf m)$ for each $(i,j)$. When
%observed $y_{inj}$ is larger for many cells, $\hat{q}_1$ is expected to be
%large.  
We next check the model fit for missing data.  We compute $\hat{q}_{ij}=
\sum_{n=1}^{N_i}\mathbb{I}(m_{inj}=1)\hat{\Prob}(z_{j \lambda_{in}}=0 \mid \by,
{\bf m})/\sum_{n=1}^{N_i}\mathbb{I}  (m_{inj}=1)$
for $(i,j)$, averaged posterior probability that a cell
with missing value for marker $j$ has a phenotype for which the marker is not
expressed in sample $i$.  That is, we examine how often a maker with expression
level not observed was estimated as no expression. Values close to 1 for
$\hat{q}$, implying that a maker is not expressed with high probability if its
expression level is not observed, comply with our subject information.  For the
four cases in the figure, $\hat{q}$ are 99\%, 100\%, 41\% and 100\%,
respectively. While $\hat{q}$ is close to 1 for the three cases in (a), (b) and
(d), $\hat{q}$ is small for the case of $i=2$ and $j=22$ in (c), possibly
because many of observed values are around zero and the missing proportion is
not large. %Figure \ref{fig:hist-pz0-missy}(a) shows the posterior inference on
%the probability $p_{inj}$ of missing in \eqref{eq:missing} for the samples.
%
%\hh {\tt You made some figures before for $p_{imj}$.  Can you make a similar
%figure for the CB data analysis and include? Temporarily I included your old
%figure.  I think that it should have three red curves, one for each
%sample.}\ech
% FIXME: I have this, but beta1 was fixed. I can run it again.
%
Figure \ref{fig:hist-pz0-missy} illustrates a histogram of $\hat{q}$ for all
$(i,j)$. The histogram is skewed such that there is a spike at 1, and most of
the time our model learns that a marker is not expressed for missing
observations.
%This complies with the subject knowledge provided by biologists. 

%{\tt 
%\begin{itemize}
%%\item check if $q$ is indexed by $i, j$.  I think it is.  if not, correct.  
%%\item Remove ``posterior prob. of expression for y'' from the figure.
%%\item No results from Flowsom??
%\end{itemize}
%}

%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t!]
\begin{center}
  \begin{tabular}{ccc}
  \includegraphics[scale=.29]{img/FlowSOM/YZ001_FlowSOM_CB.png}&
  \includegraphics[scale=.29]{img/FlowSOM/YZ002_FlowSOM_CB.png} &
  \includegraphics[scale=.29]{img/FlowSOM/YZ003_FlowSOM_CB.png} \\
  (a) Sample 1 & (b) Sample 2 &  (c) Sample 3 \\
  \end{tabular}
\end{center}
\vspace{-0.05in}
\caption{[CB data analyzed using FlowSOM]  Heatmaps of $y$ for the samples
  sorted by their cluster labels.  Cells and markers are in  rows and columns,
  respectively.  High expression levels are red, low expression levels are
  blue, missing values are white. Yellow horizontal lines divide estimated cell
  clusters.}
\label{fig:fs-post-Z}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph*{Comparison of FlowSOM and FAM for CB Data}
For comparison, we fit FlowSOM to the CB data. Since FlowSOM does not account
for different samples and missing values,
%we combined all $y_{inj}$ into one sample,
we combined all samples into one sample, and set the missing values to be the
minimum value of observed $y_{inj}$, as in the analysis of the simulated data
in \S~\ref{sec:CB-sim}.
%
Cell clustering results under FlowSOM are summarized in
Figure~\ref{fig:fs-post-Z}.  FlowSOM identified four cell clusters.  The
proportions of cells assigned to the clusters are (0.522, 0.47, 0.001, 0.006),
(0.565, 0.218, 0.192, 0.025) and (0.579, 0.247, 0.162, 0.012) for the three
samples, respectively.
%
Heterogeneity between cells in an estimated cluster under FlowSOM is greater
than that within an inferred cell phenotype under the proposed model in
Figure~\ref{fig:cb-post-Z}.  In particular, in Figure~\ref{fig:cb-post-Z},
phenotype 20 has a very distinct expression pattern compared to the other
phenotypes and its abundance estimates are $\hat{w}_{ik}=$ 15.1\%, 6.1\% and
7.6\% in the samples. On the other hand, those cells do not form a separate
cell cluster under FlowSOM.   

%%% Proportion of each cluster in each sample
%[[1]]
%   1    2    3    4
%52.2 47.0  0.1  0.6
%
%[[2]]
%   1    2    3    4
%56.5 21.8 19.2  2.5
%
%[[3]]
%   1    2    3    4
%57.9 16.2  1.2 24.7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%\begin{figure}
%\begin{center}
%\includegraphics[scale=0.5]{img/FlowSOM/compareClus_FlowSOM_CB.pdf}
%\caption{TODO: [Comparing FlowSOM phenotypes to FAM] write a caption}
%\label{fig:fs-fam-compare}
%\end{center}
%\end{figure}




%We check the posterior probabilities that a 

% if the distribution is tipped more to the positive side, and close to zero otherwise.


%At the top of each sub-figure, the sample ($i$) and marker ($j$) are listed.
%The statistic $Z_ij$ mean refers to the posterior mean proportion of cells
%that express marker $j$ in sample $i$. We expect this statistic to be close 
%to one if the distribution is tipped more to the positive side, and close to
%zero otherwise. 


%The fit is mostly good but can be poor when the number of
%observations is small. The figures are annotated with a statistic $\hat
%P(Z=0\mid m=1, \text{data})$, which is the posterior mean probability that an
%observation recorded as missing will not express a marker. We expect this
%quantity to be close to 1. This is generally the case, except for samples and
%markers where there are only a few missing values and most of the expression
%levels are high.


%The blue and grey lines represent the posterior predictive distribution and
%kernel density estiamtes  the observed data density for $y>0$.



% Since the data contains missing values, we compare
%the posterior predictive density to the observed data augmented with the
%posterior mean of the imputed data for each sample and marker.  We have
%included these figures in Appendix \ref{sec:cb-pp}. 
%At the top of each sub-figure, the sample ($i$) and marker ($j$) are listed.
%The statistic $Z_ij$ mean refers to the posterior mean proportion of cells
%that express marker $j$ in sample $i$. We expect this statistic to be close 
%to one if the distribution is tipped more to the positive side, and close to
%zero otherwise.  Within the figures, the thick grey line is the posterior
%predictive density, and the red line is the data augmented with the posterior
%mean of the imputed values.  The thin grey line is the observed data augmented
%with one sample from the posterior distribution of the imputed values.

%Another way to assess model fit is through comparing the observed data
%distribution to the posterior predictive distribution of non-missing data.
%This requires storing $\gamma_{inj}$ at each iteration of the MCMC and is quite
%expensive storage-wise. A compromise is to compare the observed data having
%positive values to the positive values in the posterior predictive
%distribution.  This comparison is provided in Appendix
%\ref{sec:cb-pp-positive}. The blue line represents the posterior predictive 
%distribution for $y>0$, and the grey line represents the observed data density
%for $y>0$. The fit is mostly good but can be poor when the number of
%observations is small. The figures are annotated with a statistic $\hat
%P(Z=0\mid m=1, \text{data})$, which is the posterior mean probability that an
%observation recorded as missing will not express a marker. We expect this
%quantity to be close to 1. This is generally the case, except for samples and
%markers where there are only a few missing values and most of the expression
%levels are high.


\subsection{Conclusions}\label{sec:CB-conc}

We have proposed a Bayesian FAM to study NK-cell diversity from mass cytometry
data in the presence of missing data. We used a simulation study to show that
our model is able to recover the true latent feature allocation matrix
generating the observed data. We are also able to learn abundances of
cell phenotypes with high accuracy, especially for prevalent phenotypes.
%
Assumptions about the missing mechanism are untestable. But through providing
an informed prior distribution on the missing mechanism, we are able to impute
data missing not at random such that most of the imputed values correspond to
the non-expression of markers. This is consistent with scientists' understanding
of CyTOF instruments.
%
While not explicitly shown, the posterior variance for $\bZ$ can be computed
easily from the posterior samples of $\bZ$ when the number of cell types $K$ is
fixed. This will help in quantifying uncertainty about the learned NK-cell
subpopulations. 
%
A simulation study comparing our model to FlowSOM shows that in some
scenarios, FlowSOM and our FAM can retrieve the same clusters, and have similar
performance. FlowSOM is orders of magnitudes faster than our model.  But we are
able to model the latent phenotype structure directly, whereas FlowSOM only
implicitly models the latent phenotypes. Our proposed FAM has may be
more effective at discovering latent phenotypes in data that comprise highly
irregularly spaced clusters of cells, at a computational cost.
%In addition, no uncertainty estimates about the latent phenotypes can be made
%using FlowSOM.
%
%{\tt you did not show any uncertainty estimates for our method.  this sounds
%like our method really bad.  you may rewrite this or show when our method
%wins.}
%
A sensitivity analysis for selecting the upper-bound for the number of latent
features $K$ in the model suggests that it is preferable to make $K$ large
enough to potentially accommodate more cell types.

When applied to real cord blood data, we observed some redundancy in phenotypes
estimates. This can be remedied using a repulsive FAM and will be included in
Project 2.

%Moreover, the ideas in this project may be extended to account for sample-specific
%covariates and time-dependency across samples. These will be explored in
%Projects 2 and 3.





\section{Project 2: Repulsive Feature Allocation Model}\label{sec:proj2}
\subsection{Introduction}
In project 2, we propose a repulsive FAM (rep-FAM), where repulsion discourages
similar features. The traditional IBP assumes a priori independence between
features and may yield redundant features. Thus, the independence assumption
may not be desirable in many applications.  The concept of repulsion is
introduced to penalize creating similar features, resulting in a more
parsimonious representation of the underlying structures.  The property of
inducing parsimony can be more critical for analyzing heterogeneous samples
collected from different backgrounds, for example, a joint analysis of cord
blood samples and samples collected from healthy subjects.  Different
approaches for repulsive models have been developed mostly in the context of
mixture models \citep{petralia2012repulsive, quinlan2017parsimonious,
xie2017bayesian, quinlan2017density}.  Independent priors for component
specific parameters in a mixture are commonly assumed. For example, in a
Dirichlet process mixture model, the atoms are iid draws from the baseline
distribution and mixture weights are constructed through stick-breaking. The
independence assumption can produce redundant mixture components located close
together, resulting in over-fitting.  To separate mixture components, the
repulsive models include a repulsion function and assume a joint model for all
component specific parameters.  The models smoothly push the components apart
based on pairwise distances through some repulsion parameters, resulting in
well separated clusters.  \cite{xu2016bayesian} innovatively used the
detrimental point process (DPP) for repulsive mixture models and feature
allocation model.  We take a different approach to create repulsive features by
exploiting repulsive mixture model developed in \cite{quinlan2017density}.  The
rep-FAM explicitly incorporates a model for the repulsion that penalizes the
inclusion of similar features, while DDP uses the determinant of a matrix as a
repulsiveness metric. Properties of the proposed rep-FAM are explored through
simulation studies and compared to the IBP. In addition, the model is further
extended to let samples possess a subset of cell phenotypes. In our
applications, some cell phenotypes can only be present in cord blood samples or
healthy-subject samples, while some cell types are shared by both.  By letting
abundances exactly be zero for some phenotypes, different sets of phenotypes
can be used to describe samples.  The remainder of this section will outline
the proposed rep-FAM in \S~\ref{sec:rep-model} and present simulation studies
to compare the rep-FAM and to the IBP in \S~\ref{sec:rep-sim}.


% TODO: 
%{\tt Read all references on repulsive models that I sent and find more and read
%them as well.}


\subsection{Probability Model}\label{sec:rep-model}
Similar to the notation in \S~\ref{prob-model}, suppose that $I$ samples are
taken from subjects, $i = 1,...,I$. Sample $i$
consists of $N_i$ cells, $n=1, \ldots, N_i$ and for each cell,
expression levels of $J$ markers are measured.  We introduce $x_i$ to denote
covariates for sample $i$.  In our data of cord blood samples and healthy
subject samples, let $x_i=0$ or 1 if sample $i$ is a cord blood sample or a
healthy subject sample, respectively.  We also let $y_{inj}$ represent the
transformed observed expression levels of marker $j$ in cell $n$ for sample $i$
and let $m_{inj}$ represent its binary missingness indicator, where $m_{inj} =
0$ if $y_{inj}$ is observed and $m_{inj} = 1$ otherwise.  We assume the
sampling distributions in \eqref{eq:y-mix} and \eqref{eq:missing} for $y_{inj}$
and $m_{inj}$.

\paragraph*{Repulsive Feature Allocation Model:} Recall that a $J\times K$ binary
matrix $\bZ$ characterizes $K$ different cell phenotypes.  Let $v_k \mid \alpha
\iid \Be(\alpha/K, 1)$, $k=1, \ldots, K.$ We define a joint distribution of
$\bZ=[\bz_1, \ldots, z_K]$ as
\begin{eqnarray}
P(\bZ \mid v, C_\phi) \propto \prod_{k=1}^K  \bc{\prod_{j=1}^J
v_k^{z_{jk}}(1-v_k)^{1-z_{jk}}} \times
\prod_{k_1=1}^{K-1}\prod_{k_2=k_1+1}^{K} \left\{1 - C_\phi\p{\rho(\bz_{k_1},
\bz_{k_2})}\right\},  \label{eq:rep-FAM}
\end{eqnarray}
where $\rho(\bz_{k_1}, \bz_{k_2})$ measure distance between columns $k_1$ and
$k_2$, for $k_1 \neq k_2$, and $C_\phi(\cdot)$ is a continuous decreasing
function in distance with $C_\phi(0)=1$ and
$\lim_{d\rightarrow\infty}C_\phi(d)= 0$. For a distance metric, we use
$\rho(\bz_{k_1}, \bz_{k_2})=\sum_{j=1}^J \abs{z_{jk_1} - z_{jk_2}}$, the number
of discordance between columns $k_1$ and $k_2$.  The function $C_\phi(\cdot)$
can be interpreted as a proximity function. A suitable form is $C_\phi(d) =
\exp\p{-d/\phi}$. \cite{quinlan2017parsimonious} showed that the model in
\eqref{eq:rep-FAM} has a finite normalizing constant and the distribution is
proper.  Under the model in \eqref{eq:rep-FAM}, probability 0 is assigned to
$\bZ$ having identical columns.  For matrices $\bZ$ that have the same number
of 0's and 1's, $\bZ$ with similar columns has a smaller probability since
$C_\phi(\cdot)$ is decreasing in distance. $C_\phi(\cdot)$ smoothly penalizes
any $\bZ$ having similar columns in the prior and can remove redundant columns in
posterior inference. Note that different from the IBP, under the model in
\eqref{eq:rep-FAM}, $\Prob(z_{jk}=1) \neq v_k$ due to the repulsive function.
We place a prior on $\alpha$, such that $\alpha \sim \text{Gamma}(a_\alpha,
b_\alpha)$.


\paragraph*{Feature Selection} We assume that cord blood samples ($x_i=0$) and
healthy subject samples ($x_i=1$) can have distinct sets of cell phenotypes.
We introduce binary indicators, $\delta_{xk}\in \{0, 1\}$, $x=0,1$, and
$k=1,\ldots, K$, to indicate whether samples from $x$ possess phenotype $k$
($\delta_{xk}=1$), or do not possess phenotype $k$ ($\delta_{xk}=0$). Assume
$\delta_{xk} \ind \Ber(p_{x})$ and $p_x \iid \Be(a_p, b_p)$.  Let the unnormalized
cell phenotype abundances be $\tilde w_{ik} \ind \G(a_W/K, 1)$, $i=1, \ldots, I$,
and $k=1, \ldots, K$. We define relative abundances in sample $i$ from
$x_i$ as 
$
w_{ik} =\tilde w_{ik} \delta_{x_i k}/\sum_{\ell=1}^K\tilde w_{i\ell} \delta_{x_i \ell}.
$
Relative abundance $w_{ik}$ is exactly zero for $\delta_{x_ik}=0$. Samples
from $x$ have the same subset of phenotypes but can have different relative
abundances over the selected phenotypes. Phenotypes with
$\delta_{0k}=\delta_{1k}=1$ appear in all samples, while some are present in only
one type of samples. Feature-selection by $\delta_{xk}$ efficiently facilitates
joint analysis of samples obtained from different sources. The model also
allows phenotypes to absent in all samples, implying that some phenotypes are not
used to describe any cells, providing a more parsimonious representation of 
cell-populations in samples. The probability models for the other parameters
remain unchanged as in \S~\ref{prob-model}.  


%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t!]
  \begin{center}
\begin{tabular}{c}
\includegraphics[scale=.6]{img/repFAM/Z_true_all.pdf}
  \end{tabular}
 \end{center}
 \vspace{-0.05in}
\caption{The transpose of $\bZ^\true$ with markers in columns and latent
phenotypes in rows. Black and white represents $z^\true_{jk}=1$ and 0,
respectively. The phenotypes and $\bw^\true_i$ are shown on the left and
right sides of each panel.  All samples share the same $\bZ^\true$ and the phenotypes are arranged in order of
$w_{ik}^\true$ within each sample.}
\label{fig:repFAM-sim-Z}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}%[th!]
\begin{figure}[t!]
  \begin{center}
  \begin{tabular}{cc}
  \includegraphics[scale=.4]{img/repFAM/TRUE/YZ001.png}&
  \includegraphics[scale=.4]{img/repFAM/TRUE/YZ002.png}\\
  {\small (a) Sample 1} & {\small(b) Sample 2} \\
  \includegraphics[scale=.4]{img/repFAM/TRUE/YZ003.png}&\\
  {\small (c) Sample 3} & \\
  \end{tabular}
  \end{center}
  \vspace{-0.05in}
  \caption{\small[Rep-FAM Simulation Study (rep-FAM prior)]  Heatmaps of $y$
    for simulated data.  Cells and markers are in rows and columns,
    respectively. Each column contains the expression levels of a marker for
    all cells in the sample.  High expression levels are red, low expression
    levels are blue, missing values are black.  Cells are rearranged by the
    corresponding posterior estimate of their phenotype indicator,
    $\hat{\lambda}_{in}$.  Yellow horizontal lines separate cells by different
    phenotypes.  At the bottom of each panel, the transpose of $\hat{\Z}_i$ and
    $\hat{\bw}_i$ are provided for each sample.  We include phenotypes having
    largest $\hat{w}_{ik}$ to explain at least 99.9\% of the cells in a sample.}
\label{fig:repFAM-TRUE-post-Z}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}%[th!]
\begin{figure}[th!]
  \begin{center}
  \begin{tabular}{cc}
  \includegraphics[scale=.4]{img/repFAM/FALSE/YZ001.png}&
  \includegraphics[scale=.4]{img/repFAM/FALSE/YZ002.png}\\
  {\small (a) Sample 1} & {\small(b) Sample 2} \\
  \includegraphics[scale=.4]{img/repFAM/FALSE/YZ003.png}&\\
  {\small (c) Sample 3} & \\
  \end{tabular}
  \end{center}
  \vspace{-0.05in}
  \caption{\small[FAM with IBP]  Heatmaps of $y$ for
    simulated data.  Cells and markers are in rows and columns, respectively.
    Each column contains the expression levels of a marker for all cells in the
    sample.  High expression levels are red, low expression levels are blue,
    missing values are black.  Cells are rearranged by the corresponding
    posterior estimate of their phenotype indicator, $\hat{\lambda}_{in}$.
    Yellow horizontal lines separate cells by different phenotypes.  At the
    bottom of each panel, the transpose of $\hat{\Z}_i$ and $\hat{\bw}_i$ are
    provided for each sample.  We include phenotypes having largest
    $\hat{w}_{ik}$ to explain at least 99.9\% of the cells in a sample.}
\label{fig:repFAM-FALSE-post-Z}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%


%TODO: HERE
\subsection{Simulation Studies}~\label{sec:rep-sim}
To better understand the behavior of the rep-FAM as a prior distribution for
the feature allocation matrix in a FAM, we performed a small-scale simulation
study. For preliminary study, we did not include $\delta_{xk}$ and kept the
same model in \S~\ref{prob-model} for $\bw_i$.   Data were simulated as
outlined in \ref{sec:CB-sim}, but with some differences as follows: The number
of observations for each sample are $N=(300, 200, 100)$, the true number of
latent features is $K^\true=4$, the number of markers is $J=5$, a hand-picked
$\bZ^\true$ was used, and the feature abundances $\bw_i^\true$ were simulated
from a Dirichlet($15, 15, 1, 1$), for each sample $i$.  The simulated
$\bZ^\true$ and $\bW^\true$ are shown in Figure \ref{fig:repFAM-sim-Z}.


We fit the FAM with the IBP in Project 1 and the rep-FAM prior. We used
the same hyperparameters as in \S~\ref{sec:CB-sim} but  with $K=10$.
%
We initialized the parameters for the MCMC simulation as outlined
in \S~\ref{sec:CB-sim}.
%
We then implemented posterior inference using MCMC simulation over 3,000
iterations, discarding the first 1,000 iterations as burn-in.  We diagnose
convergence and mixing of the described posterior MCMC simulation using trace
plots. We found no evidence of practical convergence problems. 

The posterior estimates for $\bZ$ and $\bw_i$ for the rep-FAM model and the FAM
with an IBP prior are summarized in Figures \ref{fig:repFAM-TRUE-post-Z} and
\ref{fig:repFAM-FALSE-post-Z}, respectively. The figures also include the
heatmaps of $y$ for each sample, with cells rearranged by $\hat\lambda_{in}$.
The posterior estimates for $\bZ$ and $\bw_i$ were similar to the simulation
truth in both cases. However, in the posterior estimate of $\bZ$ for the
regular FAM, features are sometimes repeated. For instance, features 10 and 7
for sample 1 in panel (a) are identical and compose 46.3\% and 2.3\% of the
cells, respectively. Similarly, features 5 and 6 are duplicates for sample 3 in
panel (c).
%
Feature 10 compose 46.3\% and 51.6\% of the data in samples 1 and 3
respectively, while feature 7 composes 2.3\% and 1.1\%, respectively in samples
1 and 3 respectively.
%
These are cases where one feature has a strong presence
in the sample, but is duplicated. In sample 3, features 5 and 6 are also
duplicates, but their presence is small in the sample, composing only 0.8\% and
0.5\% respectively.  Note that $\hat\bZ$ in the rep-FAM does not contain
duplicated features. This provides more natural interpretation of $\bZ_i$ and
$\bw_i$, and a more parsimonious representation of the cell types.
Specifically, posterior estimate $\hat\lambda_{in}$ contains only four
cell-types in the rep-FAM, and the estimated cell types are the true cell
types. In contrast, seven cell types are estimated in the FAM, but some cell
types are repeated.
%%
%Figure \ref{fig:repFAM-clus-compare} shows the cumulative proportion of the
%number of cell types. For the rep-FAM, the predominant cell type composes
%50.67\% of the data across samples, while top two predominant cell types
%compose 87.17\% of the data across samples.  For the FAM, the predominant cell
%type composes 36.3\% of the data across samples, while top two predominant
%cell types compose 68.17\% of the data across samples. Thus, we see infer that
%the rep-FAM is learning cell types that are distinct.
%%


We will further investigate the rep-FAM through intensive simulation studies
for comprehensive understanding. Also, we will analyze CB and healthy subject
samples jointly with the proposed rep-FAM with feature selection to provide
sample-specific sets of cell phenotypes.


%%cumprop.repFAM
%%        1         2         3         4
%%0.5066667 0.8716667 0.9600000 1.0000000
%%cumprop.FAM
%%        1         2         3         4         5         6         7
%%0.3633333 0.6816667 0.8700000 0.9450000 0.9850000 0.9983333 1.0000000

% TODO: HELP!
%repFAM

%\begin{figure}[H]
%\begin{center}
%\includegraphics[scale=0.5]{img/repFAM/compareClus.pdf}
%\caption{[Cumulative proportion of number of cell types] Included are the
%  cumulative proportions of the number of cell types for the rep-FAM (red)
%  and FAM (blue).}
%\label{fig:repFAM-clus-compare}
%\end{center}
%\end{figure}

%The F-score was computed from $\hat\lambda_{in}$ for each model. 
%The F-score for rep-FAM and FAM were \input{img/repFAM/fscore-rep-FAM.tex}
%and \input{img/repFAM/fscore-FAM.tex} respectively. 

%We conclude that the rep-FAM may provide a more parsimonious representation of
%the latent feature matrix $\bZ$ compared to the FAM. We therefore propose
%using rep-FAM as the prior for the feature allocation matrices in our 
%remaining projects.

\section{Project 3: Feature Allocation Model with Regression for Abundances of
Features}\label{sec:proj3}
% TODO
In Project 3, we further extend the proposed FAM to analyze samples taken at
multiple time points from a patient after NK cell infusion. Suppose $I$ samples
are taken at time points $t_1, \ldots, t_I$.   As an NK cell population evolves
over time, samples may have different sets of cell phenotypes with different
abundances. We model this process by letting phenotype abundances
$\bw_{t}=(w_{t1}, \ldots, w_{tK})$ be a function of time $(t)$ after treatment.
Inferred $\bw(t)$ reflects the evolutionary process of cell subpopulation
expansion over time.   $\bZ$ includes all phenotypes that can be possessed in a
sample, and different compositions of NK cell populations in different samples is
modeled through phenotype abundances $w_{t_i, k}$, $i=1, \ldots, I$, which
change over time in a time-dependent manner.


Similar to the model in \S~\ref{sec:proj2}, let $\xi_{t_1,k}$ represent
unnormalized abundance of phenotype $k$ in sample 1 collected at time $t_1$.
We obtain relative abundances by rescaling $w_{t_1,k}=
\xi_{t_1,k}/\sum_{\ell=1}^K \xi_{t_1, \ell}$.  We fix $\xi_{t_1,1}=a$, an
arbitrary positive number, to avoid potential identifiability issues, and let
$\xi_{t_1,k} = \max(\xi^\prime_{t_1,k}, 0)$, for $k\ge 2$, where
$\xi^\prime_{t_1,k} \iid \N(0, s^2_1)$.  Since $\xi_{t_1, 1}$ is fixed at
$a>0$, phenotype 1 is present in sample 1 and its relative abundance is
determined by $\xi_{t_1, 2}, \ldots, \xi_{t_1, K}$.  For any phenotype with
$\xi^\prime_{t_1, k} < 0$, $k=2, \ldots, K$, its relative abundance is zero and
the phenotype is absent.  That is, sample 1 can have a subset of $K$ phenotypes
and if the cells in sample 1 have the same phenotype, the phenotype is set to be
phenotype 1. Values of $a$ and $s^2_1$ need to be jointly calibrated. For the
remaining samples, we assume $\xi_{t_i,k} = \max(\xi^\prime_{t_i,k}, 0)$, $i=2,
\ldots, I$ and $k=1, \ldots, K$ with $\xi^\prime_{t_i,k} = \xi^\prime_{t_1, k}
+ f_k(t_i)$. $f_k(t)$ is a phenotype-specific function of time.
$\xi^\prime_{t_1, k}$ serves as a baseline abundance of phenotype $k$ and
$f_k(t)$ explains how abundance of phenotype $k$ changes over time.
Depending on $f_k(t)$, samples may have different subsets of phenotypes.
Various functions can be used for $f_k(t)$.  One choice for $f_k(t_i)$ is a
quadratic function in time $t$, $f_k(t) = \xi^\prime_{t_1,k} + \beta_{k1}t +
\beta_{k2}t^2$, possibly with some constraints on $\beta_{k1}$ and
$\beta_{k2}$.  For example, if $\beta_{k2} \leq 0$, the mean abundance of a
phenotype cannot increase.  We will further investigate this model so as to
accommodate biological knowledge on dynamics of cell populations in the model
for $\bw$, and potentially in the model for $\bZ$.   

%For time points $t_i$, for $i=2, \ldots, I$, we assume $\xi_{t_i,k} =
%\max(\xi^\prime_{t_i,k}, 0)$, for $k=1, \ldots, K$ with $\xi^\prime_{t_i,k} =
%f_k(t_i)$ and let $w_{t_i,k} = \xi_{t_i,k}/\sum_{\ell=1}^K \xi_{t_i,\ell}$ as
%in computing $w_{t_1,k}$. $f_k(t_i)$ is a random quantity which relates the
%previous abundance levels for phenotype $k$ to the that of the current
%time-point. One choice for $f_k(t_i)$ is a quadratic function in time $t$,
%$f_k(t) = \xi^\prime_{t_1,k} + \beta_{k1}t + \beta_{k2}t^2$, where
%$\xi_{t_1,k}$ can be interpreted as the baseline unnormalized abundance for
%phenotype $k$ and ($\beta_{k1}, \beta_{k2}$) explain change in unnormalized
%abundance over time. Alternatively, we can model the change in abundance
%through a random walk by letting $f_k(t_i) = \xi^\prime_{t_{i-1},k} +
%g_{t_i,k}$ where $g_{t_i, k} \iid \N(0, s^2)$.

%Finally, as in Project 2, we will model $\bZ$ with a rep-FAM distribution???


\section{Timeline}\label{sec:time}
%TODO
Based on the projects listed above, we propose the following timeline.  %{\tt include timeline for project 1}
 
\begin{table}[H]
  \begin{center}
    \begin{tabular}{{| l | l |}}
    \hline Project & Academic Quarter \\
    \hline
    Project 1  &   Fall 17 - Fall 18  \\
    Project 2  &   Fall 18 - Spring 19  \\
    Project 3  & Winter 19 - Fall 19  \\
    Thesis     & Fall 19 -   Winter 20  \\
    \hline
  \end{tabular}
  \end{center}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\bibliographystyle{natbib}
\bibliography{litreview.bib}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\end{document}

\appendix
\section{Posterior Computation for Project 1}
This section presents detailed derivations of the full conditional
distributions for each model parameter. Using traditional Markov
chain Monte Carlo (MCMC), we can sample from the joint posterior 
distribution of the parameters.

To sample from a distribution which is otherwise difficult to sample
from, the Metropolis-Hastings algorithm can be used. This is
particularly useful when sampling from a full conditional distribution
of one of many parameters in an MCMC based sampling scheme (such as a
Gibbs sampler). Say $B$ samples from a distribution with density
$p(\theta)$ is desired, one can do the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Provide an initial value for the sampler, e.g. $\theta^{(0)}$.
\item
  Repeat the following steps for $i = 1,\ldots,B$.
\item
  Sample a new value $\tilde\theta$ for $\theta^{(i)}$ from a
  proposal distribution $Q(\cdot \mid \theta^{(i-1)})$.

  \begin{itemize}
  \tightlist
  \item
    Let $q(\tilde\theta \mid \theta)$ be the density of the proposal
    distribution.
  \end{itemize}
\item
  Compute the ``acceptance ratio'' to be \[
     \rho=
     \min\bc{1, \frac{p(\tilde\theta)}{p(\theta^{(i-1)})} \Big/ 
            \frac{q(\tilde\theta\mid\theta^{(i-1)})}
                 {q(\theta^{(i-1)}\mid\tilde\theta)}
        }
     \]
\item
  Set \[
     \theta^{(i)} := 
     \begin{cases}
     \tilde\theta &\text{with probability } \rho \\
     \theta^{(i-1)} &\text{with probability } 1-\rho.
     \end{cases}
     \]
\end{enumerate}

Note that in the case of a symmetric proposal distribution, the
acceptance ratio simplifies further to be
$\frac{p(\tilde\theta)}{p(\theta^{(i-1)})}$.

The proposal distribution should be chosen to have the same support as
the parameter. Transforming parameters to have infinite support can,
therefore, be convenient as a Normal proposal distribution can be used.
Moreover, as previously mentioned, the use of symmetric proposal
distributions (such as the Normal distribution) can simplify the
computation of the acceptance ratio.

Some common parameter transformations are therefore presented here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For parameters bounded between $(0,1)$, a logit-transformation may
  be used. Specifically, if a random variable $X$ with density
  $f_X(x)$ has support in the unit interval, then
  $Y=\logit(X)=\log\p{\frac{p}{1-p}}$ will have density
  $f_Y(y) = f_X\p{\frac{1}{1+\exp(-y)}}\frac{e^{-y}}{(1+e^{-y})^{2}}$.
\item
  For parameters with support $(0,\infty)$, a log-transformation may
  be used. Specifically, if a random variable $X$ with density
  $f_X(x)$ has positive support, then $Y = \log(X)$ has pdf
  $f_Y(y) = f_X(e^y) e^y$.
\end{enumerate}



\vspace{5em}
\hrule
\vspace{5em}

% fc-v
\textbf{Full Conditional for $\bm v$}

The prior distribution for $v_k$ are
$v_k \mid \alpha \ind \Be(\alpha/K, 1)$, for $k = 1,...,K$. So,
$p(v_k \mid \alpha) = \alpha v_k^{\alpha/K-1}$.

Let $S = \bc{(i,n)\colon \lin = k}$.

\begin{align*}
p(v_k \mid \y, \rest) &\propto p(v_k) \prod_{j=1}^J\prod_{(i,n)\in S} p(\y \mid
  v_k, \rest) \\
&\propto (v_k)^{\alpha/K-1} \prod_{j=1}^J \prod_{(i,n)\in S}
\sum_{\ell=1}^{L^{Z_{jk}}} \eta^{Z_{jk}}_{ij\ell} \cdot
\N(y_{inj} \mid \mus_{Z_{jk}\ell}, \sss_{Z_{jk}i\ell})
\end{align*}

\mhLogitSpiel{v_k}{\xi}

Note also that $\mus_{Z_{jk}\ell}$ and $\sss_{Z_{jk}i\ell}$ are
functions of $v_k$, and should be computed accordingly. Moreover, we
will only recompute the likelihood (in the metropolis acceptance ratio)
when $Z_{jk}$ becomes different.
\vspace{2em}


% fc-alpha
\textbf{Full Conditional for $\alpha$}

\begin{align*}
p(\alpha \mid \y, \rest) &\propto p(\alpha) \times \prod_{k=1}^K p(v_k \mid
  \alpha) \\
&\propto \alpha^{a_\alpha - 1} \exp\bc{-b_\alpha \alpha} \times \prod_{k=1}^K 
\alpha~v_k^{\alpha/K} \\
&\propto \alpha^{a_\alpha + K -1} \exp\bc{-\alpha\p{b_\alpha - 
\frac{\sum_{k=1}^K \log v_k}{K}}}
\end{align*}

\[
\therefore \alpha \mid \y, \rest \sim 
\G\p{a_\alpha + K,~ b_\alpha - \frac{\sum_{k=1}^K \log v_k}{K}}
\]
\vspace{2em}


% fc-H
\textbf{Full Conditional for $\bm H$}

The prior for $\h_k$ is $\h_k \sim \N_J(0, \Gamma)$. We can
analytically compute the conditional distribution
$h_{j,k} \mid \h_{-j,k}$, which is

\[
h_{jk}  \mid \h_{-j,k} \sim \N(m_j, S^2_j),
\]

where

\[
\begin{cases}
m_j &= \bm G_{j,-j} \bm G_{-j,-j}^{-1}(\h_{-j,k})\\
S_j^2 &= \bm G_{j,j} - \bm G_{j,-j}\bm G_{-j,-j}^{-1}\bm G_{-j,j}\\
\end{cases}
\]

and the notation $\h_{-j,k}$ refers to the vector $h_k$ excluding
the $j^{th}$ element. Likewise, $\bm G_{-j,k}$ refers to the
$k^{th}$ column of the matrix $\bm G$ excluding the $j^{th}$ row.

Note that if $\bm G = \I_J$, then $m_j=0$ and $S_j^2 = 1$. Let
$S = \bc{(i,n)\colon \lin=k}$.

\begin{align*}
p(h_{jk} \mid \y, \rest)  &\propto p(h_{jk}) \prod_{(i,n) \in S} p(y_{inj} \mid
  h_{jk}, \rest) \\
%
&\propto
\exp\bc{\frac{-(h_{jk} - m_j)^2}{2S_j^2}}
 \prod_{j=1}^J \prod_{(i,n)\in S}
\sum_{\ell=1}^{L^{Z_{jk}}} \eta^{Z_{jk}}_{ij\ell} \cdot
\N(y_{inj} \mid \mus_{Z_{jk}\ell}, \sss_{Z_{jk}i\ell})
\end{align*}

\mhSpiel{h_{jk}}

Note also that $\mus_{Z_{jk}\ell}$ and $\sss_{Z_{jk}i\ell}$ are
functions of $h_{jk}$, and should be computed accordingly. Moreover,
we will only recompute the likelihood (in the metropolis acceptance
ratio) when $Z_{jk}$ becomes different.  
\vspace{2em}


% fc-lam
\textbf{Full Conditional for $\bm \lambda$}

The prior for $\lin$ is $p(\lin = k \mid \bm W_i) = W_{ik}$.

\begin{align*}
p(\lin=k\mid \y,\rest) &\propto p(\lin=k) ~ p(\y \mid \lin=k, \rest) \\
&\propto W_{ik}
\prod_{j=1}^J 
\p{
  \sum_{\ell=1}^{L^{Z_{jk}}} \eta^{Z_{jk}}_{ij\ell} \cdot
  \N(y_{inj} \mid 
  \mus_{Z_{jk}\ell}, \sss_{Z_{jk}i\ell})
}\\
\end{align*}

The normalizing constant is obtained by summing the last expression over
$k = 1,...,K$. Moreover, since $k$ is discrete, a Gibbs update can
be done on $\lin$.

\textbf{Full Conditional for $\bm W$}

The prior for $\bm{W}_i$ is $\bm W_i \sim \Dir(d, \cdots, d)$. So
the full conditional for $\bm{W}_i$ is:

\begin{align*}
p(\bm W_i \mid \rest) \propto&~~ p(\bm{W}_i) \times \prod_{n=1}^{N_i} p(\lin
  \mid \bm{W}_i)\\
\propto&~~ p(\bm{W}_i) \times \prod_{n=1}^{N_i}\prod_{k=1}^K
  W_{ik}^{\Ind{\lin=k}}\\
\propto&~~ \prod_{k=1}^K W_{ik}^{d/K-1} \times \prod_{n=1}^{N_i}\prod_{k=1}^K
  W_{ik}^{\Ind{\lin=k}}\\
\propto&~~ \prod_{k=1}^K W_{ik}^{\p{d/K + \sum_{n=1}^{N_i}\Ind{\lin=k}}-1}\\
%
\end{align*}

Therefore, \[
\bm{W}_i \mid \y,\rest ~\sim~
\Dir\p{d/K+\sum_{n=1}^{N_i}\Ind{\lambda_{i,n}=1},...,d/K+\sum_{n=1}^{N_i}\Ind{\lambda_{i,n}=K}} 
\]

Consequently, the full conditional for $\bm{W}_i$ can be sampled from
directly from a Dirichlet distribution of the form above.
\vspace{2em}


% fc-mu
\textbf{Full Conditional for $\bm\mu^\star$}

For $\mus_{0\ell}$g, let $S_{0i\ell} = \bc{(i,n,j) : \p{Z_{j,\lin} = 0
~\cap~ \gamma_{inj} = \ell}}$g and $|S_{0i\ell}|$ the cardinality of
$S_{0i\ell}$.

\newcommand\musZeroPostvarDenom{
  \frac{1}{\tau^2_0} +
  \sum_{i=1}^I\frac{|S_{0i\ell}|}{{\sigma^2}^\star_{0i\ell}}
}
\newcommand\musZeroPostMeanNum{
  \frac{\psi_0}{\tau^2_0} + 
  \sum_{i=1}^I \sum_{S_{0i\ell}}  
  \frac{y_{inj}}{{\sigma^2}^\star_{0i\ell}}
}

\begin{align*}
p(\mus_{0\ell} \mid \y, \rest) &\propto 
p(\mus_{0\ell} \mid \psi_0, \tau^2_0) \times p(\y \mid \mus_{0\ell},\rest) \\
%
&\propto
\Ind{\mus_{0\ell}<0} \exp\bc{\frac{-(\mus_{0\ell} - \psi_0)^2}{2\tau^2_{0}}}
\prod_{i=1}^I\prod_{(i,n,j)\in S_{0i\ell}} \exp\bc{\frac{-(y_{inj} -
\mus_{0\ell})^2}{2{\sigma^2}^\star_{i0\ell}}} \\
%
&\propto
\exp\bc{
  -\frac{(\mus_{0\ell})^2}{2}\p{\musZeroPostvarDenom} + 
  \mus_{0\ell}\p{\musZeroPostMeanNum}
} \\ 
& ~~~ \times \Ind{\mus_{0i\ell}<0} \\
\end{align*}

\[
\renewcommand\musZeroPostvarDenom{
  1 + \tau^2_0\sum_{i=1}^I(|S_{0i\ell}|/{\sigma^2}^\star_{0i\ell})
}
\renewcommand\musZeroPostMeanNum{
  \psi_0 + \tau^2_0 \sum_{i=1}^I\sum_{S_{0i\ell}} (y_{inj} /
  {\sigma^2}^\star_{0i\ell})
}
\therefore \mus_{0l} \mid \y, \rest \ind \N_-\p{
  \frac{\musZeroPostMeanNum}{\musZeroPostvarDenom},
  \frac{\tau^2_0}{\musZeroPostvarDenom}
}
\]

Similarly for $\mus_{1\ell}$g, let
$S_{1\ell} = \bc{(i,n,j) : \p{Z_{j,\lin} = 1 ~\cap~ \gamma_{inj} = \ell}}$g
and $|S_{1i\ell}|$ the cardinality of $S_{1i\ell}$.

\[
\newcommand\musOnePostvarDenom{
  1 + \tau^2_1 \sum_{i=1}^I (|S_{1i\ell}|/{\sigma^2}^\star_{1i\ell})
}
\newcommand\musOnePostMeanNum{
  \psi_1 + \tau^2_1 \sum_{i=1}^I \sum_{S_{1i\ell}} (y_{inj} /
  {\sigma^2}^\star_{1i\ell})
}
\therefore \mus_{1l} \mid \y, \rest \ind \N_+\p{
  \frac{\musOnePostMeanNum}{\musOnePostvarDenom},
  \frac{\tau^2_1}{\musOnePostvarDenom}
}
\]
\vspace{2em}


% fc-sig2
\textbf{Full Conditional for $\bm{{\sigma^2}}^*$}

Let
$S_{0i\ell} = \bc{(i, n,j): Z_{j,\lin} = 0 ~\cap~ \gamma_{inj}=\ell}$,
$i=1, \ldots, I$.

\begin{align*}
p(\sss_{0i\ell} \mid \y, \rest) &\propto p(\sss_{0i\ell} \mid s_i) \times p(\y
  \mid \sss_{0i\ell}, \rest) \\
&\propto (\sss_{0i\ell})^{-a_\sigma-1} \exp\bc{-\frac{s_i}{\sss_{0i\ell}}} 
\prod_{(i,n,j)\in S_{0i\ell}} \bc{
  \frac{1}{\sqrt{2\sss_{0i\ell}}}
  \exp\bc{\frac{-(y_{inj}-\mus_{0\ell})^2}{2\sss_{0i\ell}}}
} \\
&\propto (\sss_{0i\ell})^{-(a_\sigma + \frac{\abs{S_{0i\ell}}}{2})-1}
\exp\bc{\p{\frac{1}{\sss_{0i\ell}}}\p{s_i + \sum_{(i,n,j)\in S_{0i\ell}}
\frac{(y_{inj}-\mus_{0\ell})^2}{2}
}}.
\end{align*}

\[
\therefore \sss_{0i\ell} \mid \y, \rest \ind
\IG\p{a_\sigma + \frac{\abs{S_{0i\ell}}}{2}, ~~ s_i + \sum_{(i,n,j)\in S_{0i\ell}}
\frac{(y_{inj}-\mus_{0\ell})^2}{2}
}.
\]

Similarly, let
$S_{1i\ell} = \bc{(i, n,j): Z_{j,\lin} = 1 ~\cap~ \gamma_{inj}=\ell}$.
Then, the full conditional for $\sss_{1i\ell}$ is \[
\therefore \sss_{1i\ell} \mid \y, \rest \ind
\IG\p{a_\sigma + \frac{\abs{S_{1i\ell}}}{2}, ~~ s_i + \sum_{(i,n,j)\in S_{1i\ell}}
\frac{(y_{inj}-\mus_{1\ell})^2}{2}
}.
\]
\vspace{2em}


% fc-s
\textbf{Full Conditional for $s_i$}

\begin{align*}
p(s_i \mid \y, \rest) &\propto p(s_i) \times \prod_{z=0}^1 \prod_{\ell=1}^{L^z}
  p(\sss_{zi\ell} \mid s_i)\\
&\propto s_i^{a_s-1} \exp\bc{-b_s s_i} \times \prod_{z=0}^1
  \prod_{\ell=1}^{L^z} s_i^{a_\sigma} \exp\bc{-s_i / \sss_{zi\ell}} \\
&\propto s_i^{a_s + (L^0 + L^1)a_\sigma - 1} \exp\bc{-s_i \p{b_s + \sum_{z=0}^1
\sum_{\ell=1}^{L^z} 1 / \sss_{zi\ell}}}.
\end{align*}

\[
\therefore s_i \mid \y, \rest \sim 
\G\p{a_s + (L^0 + L^1)a_\sigma, ~~ b_s + \sum_{z=0}^1 \sum_{\ell=1}^{L^z}
\frac{1}{\sss_{zi\ell}} }.
\]
\vspace{2em}


% fc-gam
\textbf{Full Conditional for $\bm\gamma$}

The prior for $\gamma_{inj}$ is
$p(\gamma_{inj} = \ell \mid Z_{j\lin}=z, \eta^z_{ij\ell}) = \eta^z_{ij\ell}$,
where $\ell \in \bc{1,...,L^z}$.

\begin{align*}
p(\gamma_{inj}=\ell \mid \y, Z_{j\lin}=z, \rest) &\propto p(\gamma_{inj}=\ell)
  \times p(y_{inj} \mid \gamma_{inj}=\ell, \rest) \\
&\propto p(\gamma_{inj}=\ell) \times p(y_{inj} \mid \mus_{z\ell},
  \sss_{zi\ell}, \rest) \\
%
&\propto \eta^z_{ij\ell} \times \N(y_{inj} \mid \mus_{z\ell}, \sss_{zi\ell}) \\
&\propto \eta^z_{ij\ell} \times (\sss_{zi\ell})^{-1/2}
\exp\bc{-\frac{(y_{inj} - \mus_{z\ell})^2}{2\sss_{zi\ell}}} \\
\end{align*}

The normalizing constant is obtained by summing the last expression over
$\ell = 1,...,L^z$. Moreover, since $\ell$ is discrete, a Gibbs
update can be done on $\gamma_{inj}$.
\vspace{2em}


% fc-eta
\textbf{Full Conditional for $\bm\eta$}

The prior for $\bm\eta^z_{ij}$ is
$\bm \eta^z_{ij} \sim \Dir_{L^z}(a_{\eta^z})$, for $z\in\bc{0,1}$.
So the full conditional for $\bm\eta^z_{ij}$ is:

\begin{align*}
p(\bm \eta^z_{ij} \mid \rest) \propto&~~ p(\bm{\eta}^z_{ij}) \times
  \prod_{n=1}^{N_i} p(\gamma_{inj} \mid \bm \eta^z_{ij})\\
\propto&~~ p(\bm \eta^z_{ij}) \times \prod_{n=1}^{N_i}\prod_{\ell=1}^{L^z}
  \p{\eta^z_{ij\ell}}^{\Ind{ \gamma_{inj}=\ell ~\cap~ Z_{j\lin=z}}}\\
%
\propto&~~ \prod_{\ell=1}^{L^z} \p{\eta^z_{ij\ell}}^{a_{\eta^z}/L^z-1} \times 
\prod_{n=1}^{N_i}\prod_{\ell=1}^{L^z} \p{\eta^z_{ij\ell}}^{\Ind{
\gamma_{inj}=\ell ~\cap~ Z_{j\lin=z}}}\\
\propto&~~ \prod_{\ell=1}^{L^z} \p{\eta^z_{ij\ell}}^{\p{a_{\eta^z} / L^z +
\sum_{n=1}^{N_i} \Ind{ \gamma_{inj}=\ell ~\cap~ Z_{j\lin=z}}} - 1}\\
%
\end{align*}

Therefore, \[
\bm{\eta}^z_{ij} \mid \y,\rest ~\sim~ \Dir_{L^z}\p{a^*_1,...,a^*_{L^z}}
\] where
$a^*_\ell = a_{\eta^z}/L^z+\sum_{n=1}^{N_i}\Ind{\gamma_{inj}=\ell ~\cap~
Z_{j\lin}=z}$.
Consequently, the full conditional for $\bm{\eta}^z_{ij}$ can be
sampled from directly from a Dirichlet distribution of the form above.
\vspace{2em}


% fc-beta
\textbf{Full Conditional for $\bm\beta$}

Define $f_{inj}$ to be

\begin{align*}
f_{inj} &:= P(m_{inj} \mid p_{inj}, y_{inj}) \\
&= p_{inj}^{m_{inj}} (1-p_{inj})^{1 - m_{inj}} \\
&= \left(\frac{1}{1+e^{-x_{inj}}}
\right)^{m_{inj}}\left(\frac{1}{1+e^{x_{inj}}} \right)^{1-m_{inj}},
\end{align*}

where

\begin{align*}
  x_{inj} &:= \begin{cases}
  \beta_{0i} - \beta_{1i}(y_{inj}-c_0)^2, & \text{if } y_{inj} < c_0\nonumber \\
  \beta_{0i} - \beta_{1i}c_1\sqrt{y_{inj}-c_0}, & \text{otherwise}, \nonumber \\
  \end{cases}\\
\end{align*}

where $c_0$ and $c_1$ are real constant, $\beta_{0i} \in \mathbb{R}$, and
$\beta_{1i} > 0$.
One way to determine a prior for the missing mechanism is to first select three
points to constrain the missing mechanism $(c_\text{low}, p_\text{low})$,
$(c_0, p_0)$, and $(c_\text{high}, p_\text{high})$, and then 
solve for $\beta_0$, $\beta_1$, and $c_1$. Figure \ref{fig:prob-miss-eg} shows
an example missing mechanism where $(c_\text{low}, p_\text{low}) = (-6,0.1)$,
$(c_0, p_0)=(-2,.99)$, and $(c_\text{high}, p_\text{high}) = (-1,0.01)$.
%\beginmyfig
%\includegraphics[scale=.5]{img/prob_miss_example.pdf}
%\caption{Example missing mechanism. The blue points serve as guides in
%determining a missing mechanism. Values for $\beta$ and $c$ can be solved for
%through a system of equations.}
%\label{fig:prob-miss-eg}
%\endmyfig

Through simple algebra, we can solve for $\beta$ and $c_0$ as follows:
\begin{align*}
  \beta_0 &:= \logit(p_0) \\
  \beta_1 &:= \frac{\beta_0 - \logit(p_\text{low})}{(y_\text{low} - c_0)^2} \\
  c_1 &:= \frac{\beta_0 - \logit(p_\text{high})}{\beta_1 ~ \sqrt{y_\text{high}
  - c_0} }. \\
\end{align*}
Hence, specifying three critical points in the missing mechanism can guide
the construction of its prior distribution.
\vspace{2em}


% fc-beta_0
\textbf{Full Conditional for $\beta_{0i}$}

Recall that $\beta_{0i} \iid \N(m_{\beta_0},s^2_{\beta_0})$.

\begin{align*}
p(\beta_{0i} \mid \y, \rest) &\propto
p(\beta_{0i}) \times \prod_{n=1}^{N_i} \prod_{j=1}^J f_{inj} \\
%
&\propto \exp\bc{\frac{-(\beta_{0i}-m_{\beta_0})^2}{2s^2_{\beta_0}}}
\prod_{n=1}^{N_i} \prod_{j=1}^J f_{inj} \\
\end{align*}

\mhSpiel{\beta_{0i}}
\vspace{2em}


%fc-beta_1
\textbf{Full Conditional for $\beta_{1i}$}

Recall that $\beta_{1i}\ind \N^+(m_{\beta_1}, s^2_{\beta_1})$.
%
\begin{align*}
p(\beta_{1i} \mid \y, \rest) &\propto
p(\beta_{1i}) \times 
\prod_{n=1}^{N_i} \prod_{j=1}^J f_{inj} \\
%
&\propto \exp\bc{-\frac{(\beta_{1i} - m_{\beta_1})^2}{2s^2_{\beta_1}}}
\Ind{\beta_{1i} > 0}
\prod_{n=1}^{N_i} \prod_{j=1}^J f_{inj} \\
\end{align*}

\mhLogSpiel{\beta_{1i}}{\xi}
\vspace{2em}


% fc-y
\textbf{Full Conditional for Missing $\bm \y$}

\begin{align*}
p(y_{inj} \mid m_{inj}=1, \rest) &\propto
p(m_{inj} =1\mid y_{inj}, \rest) ~
p(y_{inj} \mid \rest) \\
%
%&\propto
%\exp\bc{\frac{-(y_{inj} - \mu_{inj})^2}{2\sigma^2_{inj}}}
%f_{inj} \\
&\propto
p_{inj} 
\sum_{\ell=1}^{L^{Z_{j\lin}}} \eta^{Z_{j\lin}}_{ij\ell} \cdot \N(y_{inj} \mid
\mu^*_{Z_{jk}, \ell}, {\sigma^2}^\star_{i,Z_{j\lin},\ell}).
\end{align*}

\mhSpiel{y_{inj}}

Note that $f_{inj}$ is a function of $y_{inj}$ and should be
computed accordingly.


\end{document}

%\section{Posterior Predictive for Observed CB Data \label{sec:cb-pp-observed}}
%\foreach \ppp in {1,...,12}{
%  \beginmyfig
%  \includegraphics[page=\ppp]{img/cb/pp_obs.pdf}
%  \caption{Posterior predictive for observed CB data for each ($i,j$) pair. Included
%  in the figures are the posterior probability that missing value in sample $i$ for
%  marker $j$ are not expressed. We expect this value to be high. The blue lines 
%  are the posterior predictive density for the observed data.
%  The grey lines are the density of observed data.}
%  \endmyfig
%}
%
%\section{Posterior Predictive for Observed Simulated Data \label{sec:sim-pp-observed}}
%\foreach \ppp in {1,...,12}{
%  \beginmyfig
%  \includegraphics[page=\ppp]{img/sim/pp_obs.pdf}
%  \caption{Posterior predictive for observed simulated data for each ($i,j$) pair. Included
%  in the figures are the posterior probability that missing value in sample $i$ for
%  marker $j$ are not expressed. We expect this value to be high. The blue lines 
%  are the posterior predictive density for the observed data.
%  The grey lines are the density of observed data.}
%  \endmyfig
%}
%\end{document}

%THIS IS MY NEW DOC


% TODO: 23 May, 2018
%more changes --
%
%1. tried to rewrite comparison to FlowSOM for simulation... but will wait for what you will have.
%
%2. rewrote the last paragraph of S2.3 for sensitivity analysis. 
%
%3. include some comparison to FlowSOM for CD data analysis.
%
%Address some small comments on page 16 (about missingness mechanism and specification of fixed hyperparameter values) and page 22 (figure for missingness mechanism and revise the comparison to FlowSOM with details).
%
%If you can do easily, use the full range of colors for heatmaps. Currently the heatmaps are misleading.   update me when you find new simulation results.
